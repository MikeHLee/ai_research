# **Contextual Stochastic Optimization for** **Omnichannel Multi-Courier Order Fulfillment** **Under Delivery Time Uncertainty**

Tinghan Ye, Sikai Cheng, Amira Hijazi, Pascal Van Hentenryck

H. Milton Stewart School of Industrial & Systems Engineering, Georgia Institute of Technology, _{_ joe.ye, sikaicheng, ahijazi6, pvh _}_ @gatech.edu


**Abstract.** _**Problem definition**_ : The paper studies a large-scale order fulfillment problem for a leading e-commerce company in the


United States. The challenge involves selecting fulfillment centers and shipping carriers with observational data only to efficiently


process orders from a vast network of physical stores and warehouses. The companyâ€™s current practice relies on heuristic rules


that choose the cheapest fulfillment and shipping options for each unit, without considering opportunities for batching items or


the reliability of carriers in meeting expected delivery dates. _**Methodology / results**_ : The paper develops a data-driven Contextual


Stochastic Optimization (CSO) framework that integrates distributional forecasts of delivery time deviations with stochastic and


robust order fulfillment optimization models. The framework optimizes the selection of fulfillment centers and carriers, accounting


for item consolidation and delivery time uncertainty. Validated on a real-world data set containing tens of thousands of products,


each with hundreds to thousands of fulfillment options, the proposed CSO framework significantly enhances the accuracy of meeting


customer-expected delivery dates compared to current practices. It provides a flexible balance between reducing fulfillment costs and


managing delivery time deviation risks, emphasizing the importance of contextual information and distributional forecasts in order


fulfillment. _**Managerial implications**_ : This is the first study of omnichannel multi-courier order fulfillment problem with delivery


time uncertainty through the lens of contextual optimization, fusing machine learning and optimization. The results offer actionable


guidance for retailers to enhance service quality and customer satisfaction while balancing cost efficiency and risk, supporting higher


retention and profitability.


**Funding:** This research was partly supported by the NSF AI Institute for Advances in Optimization (Award 2112533).


**Key words:** logistics, order fulfillment, machine learning, contextual stochastic optimization, contextual robust optimization

## **1. Introduction**


Over the past decade, online shopping has surged dramatically. The e-commerce share of total retail sales in


the United States has risen from 6% in 2015 to 16% in 2024, exceeding 1.1 trillion dollars (US Department


of Commerce 2024). Amid intense competition in pricing, service, and marketing, driven by the lucrative


e-commerce market, logistical performance has become a key element to success. Last-mile fulfillment,


in particular, is critical as it accounts for 55% of the total transportation costs in the fulfillment process


(Viswanathan 2023). This evolving market landscape poses unprecedented challenges for e-commerce


companies striving to deliver satisfactory customer services. Fortunately, the growing volume of data also


offers opportunities for data-driven operational improvements, enabling companies to boost revenue and cut


costs (Fisher et al. 2019).


In addition, after the COVID-19 pandemic, the demand for timely home delivery has also increased


significantly. As a result, omnichannel fulfillment and the use of multiple couriers, including crowd-shipping,


1


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
2


have become essential components of the fulfillment landscape, drawing significant attention both in industry


and academia (Dethlefs et al. 2022, Mohri et al. 2023, Das et al. 2023). The omnichannel approach combines


distribution centers (DCs) and brick-and-mortar stores to fulfill online orders. Unlike the traditional method


that uses DCs for online orders and stores for in-store purchases separately, the omnichannel approach


leverages the proximity of physical stores to delivery addresses. This can potentially offer more cost-effective


and faster delivery options for online customers (Acimovic and Farias 2019). Meanwhile, in the crowd

shipping model, retailers recruit non-dedicated drivers, such as gig couriers like Roadie, to handle pick-up


and delivery tasks for online customers. This approach can alleviate the workload of employed drivers during


peak hours and offer faster delivery to customers, resulting in higher service satisfaction (Zehtabian et al.


2022, Behrendt et al. 2023). _The problem considered in this paper involves fulfilling orders by choosing_


_from various types of fulfillment centers, such as warehouses and stores, and different couriers, including_


_traditional shipping companies and gig couriers._


Given that transportation and shipping are significant cost drivers in e-commerce (Dethlefs et al. 2022,


Kuhn and Sternbeck 2013, HÂ¨ubner et al. 2013), delivery consolidation has emerged as an effective strategy


for fulfilling orders with multiple items. This approach has been shown to enhance consumer satisfaction


(Wagner et al. 2023), while also reducing shipping costs for online retailers (Chen et al. 2024). In addition


to cutting parcel expenses, item consolidation enhances the customer experience by eliminating the need to


receive multiple packages for a single order. This approach not only improves convenience but also promotes


a more sustainable and environmentally friendly fulfillment process by decreasing the number of packages


shipped and the number of delivery trips needed. This reduction in shipments and trips leads to lower carbon


emissions and less packaging waste, contributing to greener logistics practices ( UlkÂ¨u 2012). [Â¨] _This paper also_


_investigates multi-item order consolidation in its omnichannel fulfillment problem._


Most existing studies on order fulfillment optimization have not explicitly considered the uncertainty in


delivery timeliness. However, Freedman (2019) highlight the strong desire of customers for accurate delivery


time promises and faster service. The survey indicates that around 44% of online shoppers have abandoned


their shopping carts because the items they wanted would not arrive on time, while 20% abandon orders with


unclear delivery dates. Furthermore, 28% of shoppers are willing to pay for expensive, expedited shipping


to receive products at their desired time. The statistics clearly show that customers prioritize service quality,


sometimes even more than the product value, when making purchase decisions. Moreover, Salari et al.


(2022) point out the importance of considering delivery time uncertainty in order fulfillment to better meet


customer expectations and improve satisfaction. Their proposed promised delivery time policy demonstrates


a 6.1% increase in sales volume in numerical experiments. Notably, overpromising delivery times can


lead to higher return rates, lower repurchase rates, and dissatisfaction with delayed service. Additionally,


customers can have mixed sentiments over underpromised delivery times, as early deliveries may not align


with their availability. Therefore, missing the exact promised delivery date can negatively impact short-term


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
3


and long-term sales, both implicitly and explicitly (Salari et al. 2022, Cui et al. 2024). _Given the crucial role_


_of delivery timeliness, the paper incorporates delivery time uncertainty into the omnichannel multi-courier_


_order fulfillment optimization problem through a contextual stochastic optimization framework._


One of the key challenges of Omnichannel Multi-Courier Order Fulfillment Optimization comes from the


nature of historical data: only observational dataâ€”i.e., delivery time deviations for the fulfillment options


actually chosenâ€”are available. Counterfactual deviations for unchosen options are never observed, similar


to the bandit feedback setting (Lattimore and SzepesvÂ´ari 2020). _The availability of observational data only,_


_raises fundamental challenges that are typically not addressed in prior work._


To address these challenges, _this paper proposes a Contextual Stochastic Optimization (CSO) framework,_


_encompassing both risk-neutral and robust approaches._ Unlike traditional stochastic programming methods


that depend on static, predefined probability distributions for uncertainties, CSO combines machine learn

ing techniques with mathematical optimization to dynamically predict uncertainties based on contextual


information. Thanks to the availability of contextual information, CSO has the flexibility of generating more


tailored and effective decisions, leveraging the most current and relevant information. Such flexibility is


particularly beneficial in the dynamic environment of online retail, where conditions and customer behaviors


can change rapidly, requiring a more responsive approach to decision making. The effectiveness of CSO


has been validated in the existing operations research and management science literature (MiË‡siÂ´c and Perakis


2020, Sadana et al. 2024). This approach has proven successful in various applications, including inventory


control (Bertsimas et al. 2016, Meller et al. 2018), price and revenue management (Ito and Fujimaki 2016,


Perakis et al. 2023), and, more recently, school redistricting (Guan et al. 2024).


**1.1.** **Contributions**


_The key novelty in this paper is a CSO framework for an omnichannel multi-courier order fulfillment_


_optimization with observational data only._ Existing studies on CSO typically assume the availability of


a dataset D = {( **s** 1 _,_ **c** 1 ) _,_ ( **s** 2 _,_ **c** 2 ) _, . . ._ }, pairing covariates with fully observed uncertain parameter vectors.


However, real-world scenarios often involve high-dimensional uncertain parameters where individual data


points capture only partial information, particularly when uncertainty measurement depends on the chosen


solution, which is the case in the application considered in this paper.


To address the challenge of observational data, this paper introduces a generalized CSO framework


addressing these real-world complexities. _The novel CSO framework is applied to a sophisticated stochastic_


_omnichannel order fulfillment optimization problem with multiple carrier options and delivery time uncer-_


_tainties._ In collaborating with a major US online retailer, the framework is rigorously evaluated on an


industrial order fulfillment dataset featuring a vast, intricate fulfillment network. This application demon

strates the framework capabilities and its potential impact on large-scale, real-world optimization challenges.


Based on the significant performance improvements demonstrated in this study, the industrial partner is


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
4


actively considering a pilot program to integrate key elements of the proposed framework into their pro

duction fulfillment optimization engine. The contributions of the paper can be summarized as follows.


1. _A modular and scalable CSO framework for observational data_ : The paper presents a novel,


distribution-agnostic contextual stochastic optimization (CSO) framework that converts problems with


missing-counterfactual observational data into tractable problems. A contextual distribution oracle is learned


from partial observations, and the resulting problem is solved via two scalable solution paradigmsâ€”


Contextual Sample Average Approximation (C-SAA) and Contextual Robust Optimization (C-RO). This


features a tractable formulation for assignment-type problems with piecewise linear objectives.


2. _Tailored contextual distribution learning for e-commerce delivery time deviations_ : The paper adapts


calibrated probabilistic multi-class classification and tree-based quantile regression to exploit the discrete,


ordinal nature of delivery time deviations, yielding well-calibrated contextual distributions for the CSO


framework.


3. _Consolidation- and timeliness-aware MILP for omnichannel, multi-courier fulfillment_ : The paper pro

poses the first data-driven mixed-integer linear program (MILP) that jointly selects fulfillment centers and


carriers and captures item-consolidation discounts while embedding learned contextual deviation distribu

tions in a tractable way.


4. _Industry-scale real-world validation_ : The paper includes an extensive case study at a major e-commerce


retailer to (1) validate the efficacy of the proposed approaches in reducing expected fulfillment costs and


(2) show significantly improvements in on-time delivery rates compared to standard heuristics and baseline


models. These results demonstrate the potential for substantial real-world impact.


**1.2.** **Structure of the Paper**


The remainder of this paper is organized as follows. Section 2 reviews related literature. Section 3 formu

lates the omnichannel multi-courier order-fulfillment problem under delivery-time deviation uncertainty.


Section 4 develops a generic contextual stochastic optimization framework for observational data and intro

duces two tractable solution paradigmsâ€”Contextual Sample Average Approximation and Contextual Robust


Optimization. Section 5 describes the machine-learning methods (multi-class classification and tree-based


quantile regression) used to implement the contextual distribution oracle. Section 6 presents the case study,


computational results, and actionable insights from a real dataset. Finally, Section 7 concludes and outlines


directions for future research.

## **2. Related Literature**


There are several streams of literature related to this paper in terms of methodology and problem context.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
5


**2.1.** **Data-Driven Decision Making**


This paper adds to the growing body of literature on data-driven decision-making, particularly at the


intersection of machine learning and optimization, which has led to the development of CSO. Sadana et al.


(2024) put forth a comprehensive survey on contextual optimization. Tutorials on various methodologies


and applications of CSO models in logistics and operations management are available in the works of MiË‡siÂ´c


and Perakis (2020), Qi and Shen (2022), and Tian et al. (2023). Among the body of research on CSO, the


most relevant to this paper are those that focus on learning contextual distributions of uncertain parameters


and incorporating these forecasts into optimization models. Data-driven approaches typically build these


forecasts from empirical residual errors (Deng and Sen 2022, Kannan et al. 2023, Perakis et al. 2023) or


weighted empirical distributions based on proximity to the training data (Bertsimas and Kallus 2020, Notz


and Pibernik 2022). However, these studies assume full observation of uncertain parameters for each data


point, which differs from the context of this paper. Recent research has also explored integrating downstream


optimization effects into ML model training. Elmachtoub and Grigas (2022) introduce the Smart Predict


then Optimize (SPO) loss and its convex surrogate for point prediction models, with subsequent extensions


to contextual distributional estimation (Qi et al. 2021, Kallus and Mao 2023). However, the SPO loss


framework is not directly applicable to this paperâ€™s context, as the dataset analyzed here is observational. In


such datasets, outcomes are only partially observed based on decisions made, presenting unique challenges


not addressed by these existing methods.


This paper thus contributes to the field of data-driven decision-making that handles observational data,


a domain explored by prior research, e.g., in Bertsimas et al. (2019) and Jo et al. (2021), using optimal


prescriptive trees for prescriptive analytics in personalized treatment. While these methods effectively


learn policies mapping features to actions, they cannot be directly applied to the fulfillment problem


considered in this paper due to the presence of instance-specific hard constraints on decisions. The proposed


framework addresses these limitations, offering a novel approach to CSO problems with observational data


and constrained decision spaces.


Unlike earlier CSO applications that focus on risk-neutral objectives, a growing stream of research is


concerned with risk-averse optimization models that incorporate contextual information (Bayram et al. 2022,


PerË‡sak and Anjos 2023, Patel et al. 2024, Sun et al. 2024). Building on these studies, this paper also adapts


traditional robust optimization models to tackle a unique CSO problem that differs from those explored in


other research.


**2.2.** **Order Fulfillment Problem**


The novelty in this paper is the application of CSO to a unique instance of the order fulfillment problem. The


order fulfillment problem has been extensively studied, and Acimovic and Farias (2019) provide a tutorial


on related algorithms developed for addressing the fulfillment optimization problem. In terms of problem


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
6


context, the most relevant works are those related to omnichannel and multi-item order fulfillment (Xu et al.


2009, Acimovic and Graves 2015, Jasin and Sinha 2015, Zhao et al. 2020, Wei et al. 2021, Ma 2023, Chen


et al. 2024). However, these works do not address fulfillment involving a variety of carrier shipping options.


Among the research on order fulfillment, demand uncertainty is the most commonly studied source of


randomness (Jasin and Sinha 2015, Zhao et al. 2020, Das et al. 2023, DeValve et al. 2023, Ma 2023). In


this paper, demand uncertainty is not considered because the focus is on a single-period order fulfillment


problem, rather than a forward-looking approach that spans multiple periods.


A few studies do address delivery time uncertainty at various stages of the order fulfillment process or


throughout the entire process. For instance, Raj et al. (2024) propose an integrated queuing model that


accounts for delivery time uncertainty in different parts of the order life cycle. They incorporate these


uncertainties into an optimization model that minimizes costs while adhering to a delivery probability


constraint to ensure on-time delivery.


In contrast to using queuing models, this study is particularly relevant to data-driven, ML-based methods


that address for delivery time uncertainty in order fulfillment. Specifically, Liu et al. (2021) integrate point


predictions of travel time with a last-mile delivery order assignment optimization problem. They propose


both a SAA model and a distributionally robust optimization (DRO) model, with the latter constructing


a moment-based ambiguity set. Similarly, Kandula et al. (2021) explore a last-mile delivery problem,


focusing on delivery success as the uncertainty. They map success probabilities to delivery times, which


are then integrated into a Vehicle Routing Problem with Time Windows. Bayram et al. (2022) study a


robust order batching optimization problem in warehouse picking and packing. They use random forest to


predict order processing time to form an uncertainty set within a robust optimization model. This paper


builds on similar concepts, developing tractable approximations and reformulations of integer programming

based optimization models. More precisely, the uncertainty in the order fulfillment problem considered in


this paper is the potential order delivery deviations, which can occur at various stages of the fulfillment


process. A similar uncertainty addressed using data-driven approach can be found in Salari et al. (2022),


who develop a quantile regression forest-based method to generate distributional forecasts of order delivery


times. Their approach then applies a decision rule, designed to balance the asymmetric costs of early and


late deliveries, to produce expected arrival times for customers. This paper differs in two key aspects. First,


the distributional forecasts are directly incorporated into contextual optimization models, eliminating the


need for a separate decision rule to generate point predictions. Second, the CSO framework proposed in this


paper is more comprehensive, accommodating multiple carrier options, whereas Salari et al. (2022) focus


on a single-carrier scenario.

## **3. The Omnichannel Multi-Courier Order Fulfillment Problem**


This section introduces a real-world order fulfillment problem encountered by the industrial partner.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
7


**3.1.** **High-Level Problem Description**


This section provides a high-level overview of the online order fulfillment challenges faced by the industrial


partner. Similar to other major e-commerce companies, tens of thousands of orders are placed continuously


throughout the day on the website and await processing. Each incoming order is organized by stock-keeping


units (SKUs), resulting in one or more order lines. For each order line, there are hundreds of fulfillment


centers across the company network eligible to source the SKUs. These centers include primarily physical


stores, as well as regional distribution centers and metro e-commerce centers. Each location is equipped


with multiple eligible carriers capable of providing different levels of service, such as Ground, Same-Day,


and Overnight shipping. Throughout this paper, â€œcarrierâ€ refers to one of these specific carrier-service pairs.


The set of available carriers spans from major shipping companies to crowdsourced gig carriers. Figure 1


illustrates the order fulfillment life cycle within the operations of the industrial partner.


**Figure 1** **The Life Cycle of the Order Fulfillment Process.**


Before making an order fulfillment decision, the company has access to both the transactional details of


the order and the real-time status of the fulfillment network. Specifically, the order information includes the


date and time the order was placed, the type, dimensions, weight, and quantities of the SKUs, the shipping


destination, and the desired delivery date. The network status data provides details on the on-hand inventory


levels of the requested SKUs and the remaining open capacities at various fulfillment centers. In addition,


each carrier provides an estimated table for shipping costs and planned time-in-transit.


Given this information, the problem is to decide which fulfillment center to source each order line from


and which carrier to use for shipping from that location. The goal is to identify the most cost-effective


fulfillment option (a location-carrier pair) while ensuring the customerâ€™s desired delivery date is met. The


uncertainty of this problem lies in the delivery timeliness performance of each fulfillment option.


**3.1.1.** **Overview of the Current Practice** Currently, the industrial partner uses a fulfillment opti

mization engine that employs a straightforward greedy algorithm. For each unit in an order, the fulfillment


optimization engine sorts the eligible location-carrier pairs by the estimated shipping costs and transit times.


There are several limitations with this approach. First, since the engine makes decisions for each unit


independently, it misses the opportunity to consolidate multiple units of the same or different products within


an order. This can lead to higher shipping costs, as the potential to reduce the number of packagesâ€”and


thereby lower shipping expensesâ€”is not fully realized.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
8


Second, the method relies solely on static transit time estimates provided by the carriers based on their


service levels to select the best carrier for meeting the promised delivery date. This approach assumes


that these estimates are always accurate. However, static transit times may not accurately reflect the actual


delivery performance of carriers. Historical data from the industrial partner reveals that over 10% of orders


experience varying degrees of early or late deliveries, which are called _deviations_ in this paper. Given the


complexity of the entire fulfillment process, these deviations can be attributed to numerous factors, such


as warehouse pick-and-pack performance, late carrier arrivals, no-shows, and external factors like extreme


weather or other unexpected circumstances. Such deviations from customer expectations can negatively


impact their experience, potentially harming the company in the long run.


**3.2.** **The Nominal Optimization Problem**


This section introduces the nominal MILP model developed for optimizing the omnichannel multi-courier


order fulfillment problem. A comprehensive list of the notations presented in this section is provided in


Appendix A for reference.


**3.2.1.** **Main Decision Variables** Let I be the set of SKUs and V be the set of fulfillment options.


Here, V is defined as the Cartesian product K Ã— L, where K denotes the set of carriers, and L denotes the


set of locations.


Each order needs to solve an independent optimization problem to decide the selection of carrier-location


pairs for each SKU. The primary decision variables are denoted by the vector **z** = ( _ğ‘§_ _ğ‘–ğ‘˜â„“_ ) _ğ‘–_ âˆˆI _,ğ‘˜_ âˆˆK _,â„“_ âˆˆL, where


each _ğ‘§_ _ğ‘–ğ‘˜â„“_ âˆˆ Z indicates the quantity of SKU _ğ‘–_ sourced from location _â„“_ and shipped by carrier _ğ‘˜_ .


**3.2.2.** **Objective Function** The objective of the optimization problem for an order is to minimize the


overall fulfillment costs while ensuring timely delivery. The fulfillment costs for an order include the fixed


fulfillment (non-parcel) costs and the shipping (parcel) costs, with consolidation discounts applied when


multiple units are assigned to the same carrier-location pair. Delivery timeliness is measured by deviations


from the desired delivery date, whether early or late. To encourage timeliness, the objective imposes penalties


for both early and late deliveries.

The objective function is formally defined as follows. Let _ğ‘_ _ğ‘–ğ‘˜â„“_ _[ğ‘ â„ğ‘–ğ‘]_ _>_ 0 be the per-unit shipping cost when

using location _â„“_ and carrier _ğ‘˜_ to fulfill SKU _ğ‘–_ . For each location _â„“_, let _ğ‘_ _â„“_ _[ğ‘“ğ‘–ğ‘¥ğ‘’ğ‘‘]_ _>_ 0 be the per-unit fixed


fulfillment cost. For each carrier _ğ‘˜_, let _ğ›½_ _ğ‘˜_ âˆˆ(0 _,_ 1) be the discount percentage applied to shipping costs


when multiple units are shipped using carrier _ğ‘˜_ from the same fulfillment center. Let _ğ›¾_ [+] â‰¥ 0 and _ğ›¾_ [âˆ’] â‰¥ 0 be


constants that convert late and early delivery penalties into per-unit costs, respectively.


In an ideal setting where all carrier-location deviations are known at the time of fulfillment, let the vector


**d** = ( _ğ‘‘_ _ğ‘˜â„“_ ) _ğ‘˜_ âˆˆK _,â„“_ âˆˆL represent the realized uncertain delivery deviations, where each _ğ‘‘_ _ğ‘˜â„“_ denotes the number


of days that the carrier-location pair ( _ğ‘˜,â„“_ ) deviates from desired delivery date. A positive deviation indicates


late delivery, a zero deviation indicates on-time delivery, and a negative deviation indicates early delivery.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
9


The weighted objective function for an order can be constructed as follows:



_ğ‘”_ ( **z** _,_ **d** ) =



_ğ‘–_ âˆˆI ï¿½ _ğ‘˜_ âˆˆK ï¿½ _â„“_ âˆˆL [[] _[ğ‘]_ _â„“_ _[ğ‘“ğ‘–ğ‘¥ğ‘’ğ‘‘]_ + (1 âˆ’ _ğ›½_ _ğ‘˜_ ) _ğ‘_ _ğ‘–ğ‘˜â„“_ _[ğ‘ â„ğ‘–ğ‘]_ [+] _[ ğ›¾]_ [+] _[ğ‘‘]_ [+] _ğ‘˜â„“_ [+] _[ ğ›¾]_ [âˆ’] _[ğ‘‘]_ _ğ‘˜â„“_ [âˆ’] []] _[ğ‘§]_ _[ğ‘–ğ‘˜â„“]_ if [ï¿½] _ğ‘–_ âˆˆI _[ğ‘§]_ _ğ‘–ğ‘˜â„“_ [â‰¥] [2] _[,]_
(1)
ï¿½ï¿½ï¿½ _ğ‘–_ âˆˆI ï¿½ _ğ‘˜_ âˆˆK ï¿½ _â„“_ âˆˆL [(] _[ğ‘]_ _â„“_ _[ğ‘“ğ‘–ğ‘¥ğ‘’ğ‘‘]_ + _ğ‘_ _ğ‘–ğ‘˜â„“_ _[ğ‘ â„ğ‘–ğ‘]_ [+] _[ ğ›¾]_ [+] _[ğ‘‘]_ [+] _ğ‘˜â„“_ [+] _[ ğ›¾]_ [âˆ’] _[ğ‘‘]_ _ğ‘˜â„“_ [âˆ’] [)] _[ğ‘§]_ _[ğ‘–ğ‘˜â„“]_ otherwise _,_



where _ğ‘‘_ [+]
_ğ‘˜â„“_ [=][ max][{][0] _[, ğ‘‘]_ _[ğ‘˜â„“]_ [}] [ and] _[ ğ‘‘]_ _ğ‘˜â„“_ [âˆ’] [=][ max][{][0] _[,]_ [âˆ’] _[ğ‘‘]_ _[ğ‘˜â„“]_ [}] [. This objective function encourages item consolidation]


within an order by applying a carrier-specific discount if at least two units are sourced from the same


location and shipped by the same carrier. In addition, it leverages an asymmetric penalty cost function for


delivery deviations, where _ğ›¾_ [+] â‰« _ğ›¾_ [âˆ’] . This asymmetry strongly penalizes late deliveries to discourage delays


while also applying a smaller penalty to disincentivize early deliveries. Specifically, the penalties can be


interpreted as the opportunity cost associated with early deliveries and the lost-sale cost associated with late


deliveries. The objective function is piecewise linear and can be linearized using standard rewritings.


**3.2.3.** **Operational Constraints** Several operational constraints ensure that the selection of fulfill

ment center locations and carriers is feasible in practice. For location _â„“_ âˆˆL, let inv _ğ‘–â„“_ â‰¥ 0 be the inventory


level of SKU _ğ‘–_ at location _â„“_ and cap _â„“_ â‰¥ 0 be the available capacity at location _â„“_ when the order is placed.


Let _ğ‘_ _ğ‘–_ â‰¥ 0 be the quantity of SKU _ğ‘–_ in the order, and let _ğ‘’_ _ğ‘–ğ‘˜â„“_ âˆˆ{0 _,_ 1} be a binary indicator of whether the


location-carrier pair ( _â„“, ğ‘˜_ ) is an eligible fulfillment option for SKU _ğ‘–_ . An assignment **z** in the feasible set Z


must obey the following constraints.


  - Each unit of an SKU must be sourced from exactly one location and shipped by exactly one carrier.



âˆ‘ï¸

_ğ‘˜_ âˆˆK



_ğ‘§_ _ğ‘–ğ‘˜â„“_ = _ğ‘_ _ğ‘–_ _,_ âˆ€ _ğ‘–_ âˆˆI (2)

âˆ‘ï¸

_â„“_ âˆˆL




  - Each SKU can only be fulfilled by eligible candidate location-carrier pairs, which may vary depending


on the carrierâ€™s coverage and package requirements.


_ğ‘§_ _ğ‘–ğ‘˜â„“_ â‰¤ _ğ‘_ _ğ‘–_ _ğ‘’_ _ğ‘–ğ‘˜â„“_ _,_ âˆ€ _ğ‘–_ âˆˆI _, ğ‘˜_ âˆˆK _,â„“_ âˆˆL (3)


  - Only locations with available inventory of the requested SKUs can be chosen.


_ğ‘§_ _ğ‘–ğ‘˜â„“_ â‰¤ inv _ğ‘–â„“_ _,_ âˆ€ _ğ‘–_ âˆˆI _,â„“_ âˆˆL (4)

âˆ‘ï¸

_ğ‘˜_ âˆˆK


  - Each location has a daily capacity limit on the total number of units it can process.



âˆ‘ï¸

_ğ‘–_ âˆˆI



âˆ‘ï¸ _ğ‘§_ _ğ‘–ğ‘˜â„“_ â‰¤ cap _â„“_ _,_ âˆ€ _â„“_ âˆˆL (5)

_ğ‘˜_ âˆˆK


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
10


**3.3.** **The Contextual Stochastic Order Fulfillment Problem**


In practice, the delivery deviations of each carrier-location pair cannot be perfectly estimated in advance. To


account for this uncertainty for each order, this section models the vector of uncertain delivery deviations

Ëœ
**d** = ( Ëœ _ğ‘‘_ _ğ‘˜â„“_ ) _ğ‘˜_ âˆˆK _,â„“_ âˆˆL âˆ¼ P as a (|K||L|) -dimensional random vector governed by a joint probability distribution

P . Since deviations measured in days only take on discrete values in the dataset, each _ğ‘‘_ [Ëœ] _ğ‘˜â„“_ inherently follows a


discrete probability distribution. It is further assumed that every _ğ‘‘_ [Ëœ] _ğ‘˜â„“_ shares the same finite, ordered support.


To formalize this, let _ğ¶_ be the total number of distinct deviation values and denote them by _ğœ‰_ 1 _< ğœ‰_ 2 _< . . . < ğœ‰_ _ğ¶_ .


By definition, any realization _ğ‘‘_ _ğ‘˜â„“_ of _ğ‘‘_ [Ëœ] _ğ‘˜â„“_ must lie in this set: _ğ‘‘_ _ğ‘˜â„“_ âˆˆ{ _ğœ‰_ 1 _, ğœ‰_ 2 _, . . ., ğœ‰_ _ğ¶_ } _._


In addition, let **s** = ( **s** _ğ‘˜â„“_ ) _ğ‘˜_ âˆˆK _,â„“_ âˆˆL denote the state vector observable to the order before the fulfillment


decision is made, where each **s** _ğ‘˜â„“_ is a vector of covariates encompassing information about order details and


fulfillment network status related to carrier-location pair ( _ğ‘˜,â„“_ ) . The contextual distribution of the deviation


vector, upon observing **s**, is denoted by P( **d** | **s** ), and the individual deviation contextual distribution is


P _ğ‘˜â„“_ ( _ğ‘‘_ _ğ‘˜â„“_ | **s** _ğ‘˜â„“_ ) for each _ğ‘˜_ âˆˆK and _â„“_ âˆˆL .


This leads to the following contextual stochastic order fulfillment problem (CSOFP):


(CSOFP) min **z** âˆˆZ [E] **[d]** [Ëœ] [âˆ¼][P][(] **[d]** [|] **[s]** [)] [ [] _[ğ‘”]_ [(] **[z]** _[,]_ [ Ëœ] **[d]** [)]] _[.]_ (6)


Solving Problem (6) in practice requires leveraging data from past orders. Unlike classical CSO formula

tions where the entire random cost vector is observed, CSOFP is based on an observational dataset of past


decisions and their realized costs. Let O be the set of historical orders. For each _ğ‘œ_ âˆˆO _,_ define the decision


vector **z** _ğ‘œ_ = ( _ğ‘§_ _ğ‘–ğ‘˜â„“,ğ‘œ_ ) _ğ‘–_ âˆˆI _,ğ‘˜_ âˆˆK _,â„“_ âˆˆL _._ Since deviations were observed only for chosen ( _ğ‘–, ğ‘˜,â„“_ ) triples, the full


deviation vector **d** _ğ‘œ_ = ( _ğ‘‘_ _ğ‘˜â„“,ğ‘œ_ ) _ğ‘˜_ âˆˆK _,â„“_ âˆˆL contains many unobserved entries. The subset of realized deviations


for order _ğ‘œ_ is:

**D** _ğ‘œ_ := { _ğ‘‘_ _ğ‘˜â„“,ğ‘œ_ | âˆ‘ï¸ _ğ‘§_ _ğ‘–ğ‘˜â„“,ğ‘œ_ _>_ 0 _, ğ‘˜_ âˆˆK _,â„“_ âˆˆL} _._

_ğ‘–_ âˆˆI

The resulting dataset available for estimating the contextual distribution P( **d** | **s** ) is D = {( **s** _ğ‘œ_ _,_ **D** _ğ‘œ_ )} _ğ‘œ_ [| O|] =1 [.]

## **4. Methodology: A CSO Framework for Observational Data**


Solving CSOFP under observational data requires: (1) learning a contextual distributional oracle from partial


realizations, and (2) optimizing with that oracle in a tractable way.


This section lays out a contextual stochastic optimization (CSO) framework that does exactly that. In


Section 4.1, a generic CSO problem (denoted by P ) is defined. Section 4.2 shows how to construct a


contextual distribution oracle M( **s** ) from partial observations. Sections 4.3 and 4.4 introduce two solution


paradigmsâ€”Contextual Sample Average Approximation and Contextual Robust Optimizationâ€”which use


M( **s** ) as input. Finally, Section 4.6 maps all of the above back to the omnichannel multi-courier CSOFP


introduced in Section 3. Figure 2 provides a schematic overview of the proposed framework, illustrating


the flow from historical observational data through the learning and optimization stages to produce a final


decision.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
11


**Figure 2** **A Schematic Overview of the CSO Framework for Observational Data.**


**4.1.** **Generic Contextual Stochastic Optimization (CSO) Problem**


Problem P consists of fulfilling a set of incoming requests sequentially, each of which specifies demands


for a subset of products. Let I be the set of products, V the set of selection options (e.g., fulfillment or

transport modes), and Z âŠ† Z + [|I|Ã—|V|] the feasible assignment set. Each request arrives with known demand


quantities { _ğ‘_ _ğ‘–_ : _ğ‘–_ âˆˆI} at decision time. The decision variable **z** = ( _ğ‘§_ _ğ‘–ğ‘£_ ) _ğ‘–_ âˆˆI _, ğ‘£_ âˆˆV âˆˆZ assigns quantity _ğ‘§_ _ğ‘–ğ‘£_ of


product _ğ‘–_ to option _ğ‘£_ .


Let Ëœ **c** = ( Ëœ _ğ‘_ _ğ‘–ğ‘£_ ) _ğ‘–_ âˆˆI _, ğ‘£_ âˆˆV âˆ¼ P denote the random cost vector. Assume that Ëœ **c** is element-wise positive and the


cost function _ğ‘”_ ( **z** _,_ Ëœ **c** ) is piecewise linear in **z** . Introduce, for _ğ‘—_ = 0 _,_ 1 _, . . ., ğ‘›_, the breakpoint vectors



**b** _[ğ‘—]_ = [ï¿½] _ğ‘_ _ğ‘–ğ‘£_ _[ğ‘—]_ ï¿½


so that each segment is defined as



_ğ‘–_ âˆˆI _, ğ‘£_ âˆˆV _[,]_ **[ b]** [0] _[ <]_ **[ b]** [1] _[ <]_ [ Â· Â· Â·] _[ <]_ **[ b]** _[ğ‘›]_ ( component-wise ) _,_




[ **b** _[ğ‘—]_ [âˆ’][1] _,_ **b** _[ğ‘—]_ ] = ï¿½ **z** : _ğ‘_ _ğ‘–ğ‘£_ _[ğ‘—]_ [âˆ’][1] â‰¤ _ğ‘§_ _ğ‘–ğ‘£_ â‰¤ _ğ‘_ _ğ‘–ğ‘£_ _[ğ‘—]_ [âˆ€] _[ğ‘–]_ [âˆˆI] _[, ğ‘£]_ [âˆˆV] ï¿½ _._


Let **a** _[ğ‘—]_ = ( _ğ‘_ _ğ‘–ğ‘£_ _[ğ‘—]_ [)] _[ğ‘–]_ [âˆˆI] _[, ğ‘£]_ [âˆˆV] [ be the marginal-cost adjustment on segment] _[ ğ‘—]_ [. Then]


_ğ‘”_ ( **z** _,_ Ëœ **c** ) = ( **c** Ëœ + **a** _[ğ‘—]_ ) [T] **z** if **z** âˆˆ[ **b** _[ğ‘—]_ [âˆ’][1] _,_ **b** _[ğ‘—]_ ] _, ğ‘—_ = 1 _, . . ., ğ‘›,_ (7)


thereby capturing volume-dependent pricing behaviors.


For each request, the fulfillment decision solves the risk-neutral stochastic optimization problem


min ï¿½ _ğ‘”_ ( **z** _,_ Ëœ **c** )ï¿½ _._ (8)
**z** âˆˆZ [E] **[c]** [Ëœ][âˆ¼][P]


The piecewise-linear cost in (7) partitions the decision space into shipment-size tiers determined by the


breakpoints { **b** _[ğ‘—]_ } . Within tier _ğ‘—_, the marginal cost is Ëœ **c** + **a** _[ğ‘—]_, which shifts to Ëœ **c** + **a** _[ğ‘—]_ [+][1] upon entering tier


_ğ‘—_ + 1 . This formulation accommodates economies of scale (declining unit costs at higher volumes), quantity


discounts (step-down pricing beyond thresholds), capacity surcharges (unit-cost premiums when exceeding


lower-cost bands), and other tiered-pricing schemes.


In Problem (8), the true distribution P is not readily available. However, side information often exists


for each product-option pair. Let **s** _ğ‘–ğ‘£_ denote the covariate vector for product _ğ‘–_ under selection option _ğ‘£_


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
12


(e.g., network state, weather, current demand). All these covariate vectors are aggregated into the state


vector **s** = ( **s** _ğ‘–ğ‘£_ ) _ğ‘–_ âˆˆI _,ğ‘£_ âˆˆV, which encompasses all contextual information available at the time of decision.


The distribution P is then approximated by the conditional distribution P( **c** | **s** ), yielding the Contextual


Stochastic Optimization (CSO) problem


min
**z** âˆˆZ [E] **[c]** [Ëœ][âˆ¼][P][(] **[c]** [|] **[s]** [)] [ [] _[ğ‘”]_ [(] **[z]** _[,]_ **[ Ëœc]** [)]] _[.]_ (9)


Let Ëœ **c** _ğ‘£_ = ( Ëœ _ğ‘_ _ğ‘–ğ‘£_ ) _ğ‘–_ âˆˆI and **s** _ğ‘£_ = ( **s** _ğ‘–ğ‘£_ ) _ğ‘–_ âˆˆI for each _ğ‘£_ âˆˆV . Under the assumption that, conditional on its own


covariates, each component _ğ‘_ _ğ‘£_ is independent across options _ğ‘£_ âˆˆV, one has


P( **c** | **s** ) = Î  _ğ‘£_ âˆˆV P _ğ‘£_ ( **c** _ğ‘£_ | **s** _ğ‘£_ ) _,_


where P _ğ‘£_ (Â· | **s** _ğ‘£_ ) is the contextual distribution for option _ğ‘£_ . This assumption is reasonable when each optionâ€™s


cost depends primarily on its own covariates. Shared features, such as weather, create similarity but do not


induce direct dependence. Consequently, Problem (9) can be written as


min
**z** âˆˆZ [E] **[c]** [Ëœ][âˆ¼][Î ] _[ğ‘£]_ [âˆˆV] [P] _[ğ‘£]_ [(] **[c]** _[ğ‘£]_ [|] **[s]** _[ğ‘£]_ [)] [ [] _[ğ‘”]_ [(] **[z]** _[,]_ **[ Ëœc]** [)]] _[.]_ (10)


**4.2.** **Constructing a Contextual Distribution Oracle from Observational Data**


The contextual distribution P( **c** | **s** ) is also generally unknown but can often be inferred from historical


observations. In many real-world COS applications (including CSOFP) however, data are observational, i.e.,


only the costs corresponding to decisions actually taken were recorded. As a result, the dataset available to

estimate P( **c** | **s** ) takes the form D = {( **s** _ğ‘œ_ _,_ **C** _ğ‘œ_ )} _ğ‘œ_ [|][D] = [|] 1 [, where] **[ s]** _[ğ‘œ]_ [=][ (] _[ğ‘ ]_ _[ğ‘–ğ‘£,ğ‘œ]_ [)] _[ğ‘–]_ [âˆˆI] _[, ğ‘£]_ [âˆˆV] [ and] **[ C]** _[ğ‘œ]_ [=][ (] **[c]** _[ğ‘£,ğ‘œ]_ [)] _[ğ‘£]_ [âˆˆV] [ collect]


the context and realized costs, with **c** _ğ‘£,ğ‘œ_ observed only if option _ğ‘£_ was selected in request _ğ‘œ_ .


The learning task consists in finding a full-vector forecasting oracle M that approximates P( **c** | **s** ) in a


supervised manner using the dataset D : M receives a context **s** as input and returns a probability distribution


M( **s** ) on the cost vector Ëœ **c** . Under the conditional independence assumption from the previous section,


learning P( **c** | **s** ) amounts to learning P _ğ‘£_ ( **c** _ğ‘£_ | **s** _ğ‘£_ ) for each selection option _ğ‘£_ separately. Partition the full


dataset D into subsets D _ğ‘£_ = {( **s** _ğ‘£,_ 1 _,_ **c** _ğ‘£,_ 1 ) _,_ ( **s** _ğ‘£,_ 2 _,_ **c** _ğ‘£,_ 2 ) _, . . ._ } _,_ representing the dataset for option _ğ‘£_ . A machine


learning model M _ğ‘£_ is then trained on D _ğ‘£_ to approximate each P _ğ‘£_ ( **c** _ğ‘£_ | **s** _ğ‘£_ ) . Assemble the oracle as the product



M( **s** ) = [ï¿½] M _ğ‘£_ ( **s** _ğ‘£_ ) [ï¿½]



_ğ‘£_ âˆˆV _[,]_ [ which generates joint forecasts by treating each component independently. Note that]



if every **s** _ğ‘£_ shares the same structure and dimension, a single learning architecture can serve as M _ğ‘£_ for all


_ğ‘£_ âˆˆV, trained on the union âˆª _ğ‘£_ âˆˆV D _ğ‘£_ .


By reducing the high-dimensional joint learning task to |V| manageable subproblems, this decomposition


turns observational data into a black-box contextual distribution oracle M( **s** ), which will serve as the input


for the solution methods developed in Section 4.3 (C-SAA) and Section 4.4 (C-RO).


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
13


**4.3.** **Contextual Sample Average Approximation (C-SAA)**


Problem (10) is approximated by generalizing the Sample Average Approximation (SAA) method (Kleywegt


et al. 2002) to contextual stochastic optimization. Given a request with covariates **s**, the Contextual Sample


Average Approximation (C-SAA) proceeds in two stages:


1. **Candidate generation.**

(a) Draw _ğ‘_ 1 independent cost vector samples { _ğƒ_ _[ğ‘›]_ } _ğ‘›_ _[ğ‘]_ = [1] 1 [âˆ¼M(] **[s]** [)] [, where] _[ ğƒ]_ _[ğ‘›]_ [=][ (] _[ğœ‰]_ _ğ‘–ğ‘£_ _[ğ‘›]_ [)] _[ğ‘–]_ [âˆˆI] _[, ğ‘£]_ [âˆˆV] [.]


(b) Solve



1
**z** _ğ‘–_ = argmin
**z** âˆˆZ _ğ‘_ 1



_ğ‘_ 1

_ğ‘”_ ( **z** _, ğƒ_ _[ğ‘›]_ ) _,_ _ğ‘–_ = 1 _, . . .,ğ‘„,_

âˆ‘ï¸

_ğ‘›_ =1



independently _ğ‘„_ times to obtain candidate solutions { **z** 1 _, . . .,_ **z** _ğ‘„_ } with sample-average objectives


{ _ğ‘“_ 1 _, . . ., ğ‘“_ _ğ‘„_ } .

(c) Compute the average objective Â¯ _ğ‘“_ = _ğ‘„_ [1] ï¿½ _ğ‘–ğ‘„_ =1 _[ğ‘“]_ _[ğ‘–]_ [, which is a statistical lower bound on the true optimal]


value _ğ‘“_ [âˆ—] because Â¯ _ğ‘“_ is an unbiased estimator of E **c** Ëœâˆ¼P( **c** | **s** ) [Â¯ _ğ‘“_ ] and E **c** Ëœâˆ¼P( **c** | **s** ) [Â¯ _ğ‘“_ ] â‰¤ _ğ‘“_ [âˆ—] .


2. **Candidate evaluation.**


(a) For each **z** _ğ‘–_, draw a larger set of evaluation samples { _ğƒ_ _[ğ‘›]_ } _ğ‘›_ _[ğ‘]_ = [2] 1 [âˆ¼M(] **[s]** [)] [, with] _[ ğ‘]_ [2] [ â‰«] _[ğ‘]_ [1] [.]

(b) Compute the re-estimated objectives _ğ‘“_ [Â¯] ( **z** _ğ‘–_ ) = _ğ‘_ [1] 2 ï¿½ _ğ‘›ğ‘_ = 2 1 _[ğ‘”]_ [(] **[z]** _[ğ‘–]_ _[,][ ğƒ]_ _[ğ‘›]_ [)] [.]

(c) Each _ğ‘“_ [Â¯] ( **z** _ğ‘–_ ) is an upper bound on _ğ‘“_ [âˆ—] since each candidate solution is feasible; the difference


Â¯
_ğ‘“_ ( **z** _ğ‘–_ ) âˆ’ Â¯ _ğ‘“_ approximates the optimality gap.


(d) Select the candidate **z** [âˆ—] with the smallest estimated gap.


**Discussion.** Unlike the reweighting approach of Bertsimas and Kallus (2020), which leverages complete


historical samples for each fully-observed cost vector, Câ€“SAA relies solely on observational data (i.e., only


the costs of the selected options are available). Attempting to form all possible cost vector combinations


from partial observations would lead to a combinatorial explosion as |V| and |D| grow, making such method


intractable in large, high-dimensional selection spaces.


**4.4.** **Contextual Robust Optimization (C-RO)**


The performance of C-SAA largely hinges on the accuracy of the estimated contextual distribution. Robust


optimization provides a hedge against misspecification of the contextual distribution by guarding against


worstâ€“case scenarios, making it a viable approach for contextual stochastic optimization. Let U( **s** ) âŠ‚


R [|I|Ã—|V|] represent a contextual uncertainty set for the cost vector Ëœ **c** . The Contextual Robust Optimization


(C-RO) problem is


min
**z** âˆˆZ _**ğƒ**_ [max] âˆˆU( **s** ) _[ğ‘”]_ [(] **[z]** _[,][ ğƒ]_ [)] _[.]_ (11)


Two constructions of U( **s** ) are considered: a discrete samplingâ€“based set U _ğ‘‘_ ( **s** ) and a budgeted interval


set U _ğ‘_ ( **s** _, ğµ_ ) .


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
14


**4.4.1.** **Contextual Discrete Uncertainty Set** Problem (11) can be reformulated into a single-level


problem by enumerating every possible realization of the random vector Ëœ **c**, a standard technique in robust


optimization. In principle, a discrete distribution can be generated as mentioned before, by combining all


combinations of the observed data points. However, this will make the problem intractable as discussed.


To retain tractability, a sampling-based discrete uncertainty set in the same spirit of C-SAA is introduced.


Let U _ğ‘‘_ ( **s** ) = { _ğƒ_ [1] _, . . ., ğƒ_ _[ğ‘]_ } denote a collection of _ğ‘_ deviation scenarios drawn from M( **s** ) . The robust


counterpart of (11) becomes


(C-RO-D) min _ğ‘¡_
**z** âˆˆZ _, ğ‘¡_ âˆˆR (12)

s.t. _ğ‘¡_ â‰¥ _ğ‘”_ ( **z** _, ğƒ_ _[ğ‘›]_ ) _,_ _ğ‘›_ = 1 _, . . ., ğ‘._


**4.4.2.** **Contextual Budgeted Interval Uncertainty Set** An alternative uncertainty set is the bud

geted interval set U _ğ‘_ ( **s** _, ğµ_ ) (Bertsimas and Sim 2004), which is defined by a robust budget _ğµ_ . This budget


limits the extent to which limits how many components of the uncertain parameter Ëœ **c** can simultaneously


deviate to their upper bounds.


Rather than estimating the full joint distribution, only the conditional lower and upper quantiles at levels


_ğ‘_ low and _ğ‘_ up are needed to define a ( _ğ‘_ low _, ğ‘_ up ) prediction interval for each option.



For each option _ğ‘£_ âˆˆV, let _ğƒ_ _ğ‘£_ = [ï¿½] _ğœ‰_ _ğ‘–ğ‘£_ ï¿½ _ğ‘–_ âˆˆI [and] _[ ğƒ]_ _[ğ‘£]_ [=][ ï¿½] _[ğœ‰]_ _[ğ‘–ğ‘£]_ ï¿½


_ğ‘_ up -quantiles extracted from M _ğ‘£_ ( **s** _ğ‘£_ ) :



_ğ‘–_ âˆˆI [denote the estimated conditional] _[ ğ‘]_ [low] [- and]



_ğƒ_ _ğ‘£_ = inf{ **u** : P _ğ‘£_ ( **c** _ğ‘£_ â‰¤ **u** | **s** _ğ‘£_ ) â‰¥ _ğ‘_ low } _,_ _ğƒ_ _ğ‘£_ = inf{ **u** : P _ğ‘£_ ( **c** _ğ‘£_ â‰¤ **u** | **s** _ğ‘£_ ) â‰¥ _ğ‘_ up } _._


Given a budget _ğµ_, the budgeted interval uncertainty set is


U _ğ‘_ ( **s** _, ğµ_ ) = ï¿½ _ğƒ_ : _ğœ‰_ _ğ‘–ğ‘£_ = _ğœ‰_ _ğ‘–ğ‘£_ + _ğ›¿_ _ğ‘–ğ‘£_ ( _ğœ‰_ _ğ‘–ğ‘£_ âˆ’ _ğœ‰_ ~~_ğ‘–_~~ _ğ‘£_ ) _,_ âˆ‘ï¸ _ğ›¿_ _ğ‘–ğ‘£_ â‰¤ _ğµ, ğ›¿_ _ğ‘–ğ‘£_ âˆˆ[0 _,_ 1]ï¿½ _._

_ğ‘–,ğ‘£_


With a fixed **z**, the inner maximization problem in (11) is



max
_ğ›¿_ _ğ‘–ğ‘£_



âˆ‘ï¸( _ğœ‰_ _ğ‘–ğ‘£_ âˆ’ _ğœ‰_ ~~_ğ‘–_~~ _ğ‘£_ ) _ğ‘§_ _ğ‘–ğ‘£_ _ğ›¿_ _ğ‘–ğ‘£_ (13)

_ğ‘–,ğ‘£_



s.t. _ğ›¿_ _ğ‘–ğ‘£_ â‰¤ _ğµ_ (14)
âˆ‘ï¸

_ğ‘–,ğ‘£_



_ğ›¿_ _ğ‘–ğ‘£_ âˆˆ[0 _,_ 1] _,_ âˆ€ _ğ‘–, ğ‘£._ (15)


Let _ğ‘¦_ _ğ‘—_ âˆˆ{0 _,_ 1} and _ğ‘¤_ _ğ‘–ğ‘£_ _[ğ‘—]_ [â‰¥] [0] [ be auxiliary variables. Denote by] _[ ğœ‹]_ [â‰¥] [0] [ and] _[ ğœ†]_ _[ğ‘–ğ‘£]_ [â‰¥] [0] [ the dual variables]


corresponding to Constraints (14) and (15), respectively. Finally, let _ğ‘€_ be a sufficiently large constant. A


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
15


valid choice for the â€œbig-Mâ€ constant is _ğ‘€_ = max _ğ‘–,ğ‘£, ğ‘—_ ï¿½ _ğ‘_ _ğ‘–ğ‘£_ _[ğ‘›]_ [âˆ’] _[ğ‘]_ _ğ‘–ğ‘£_ [1] _[, ğ‘]_ _ğ‘–ğ‘£_ _[ğ‘›]_ [âˆ’][1] _,_ ( _ğœ‰_ ~~_ğ‘–_~~ _ğ‘£_ + _ğ‘_ _ğ‘–ğ‘£_ _[ğ‘—]_ [)] _[ ğ‘]_ _ğ‘–ğ‘£_ _[ğ‘›]_ ï¿½ _._ By taking the dual

of the inner maximization problem and introducing _ğ‘¦_ _ğ‘—_ and _ğ‘¤_ _ğ‘–ğ‘£_ _[ğ‘—]_ [, a robust counterpart of (11) is obtained as]



(C-RO-B) min (
**z** âˆˆZ _,ğ‘¦,ğ‘¤,ğœ‹,ğœ†_ âˆ‘ï¸



_ğœ†_ _ğ‘–ğ‘£_ )

_ğ‘–,ğ‘£_



_ğ‘¤_ _[ğ‘—]_

âˆ‘ï¸ _ğ‘–ğ‘£_ [+] _[ ğœ‹ğµ]_ [+] âˆ‘ï¸

_ğ‘–,ğ‘£, ğ‘—_ _ğ‘–,ğ‘£_



s.t. _ğœ‹_ + _ğœ†_ _ğ‘–ğ‘£_ â‰¥( _ğœ‰_ _ğ‘–ğ‘£_ âˆ’ _ğœ‰_ ~~_ğ‘–_~~ _ğ‘£_ ) _ğ‘§_ _ğ‘–ğ‘£_ _,_ âˆ€ _ğ‘–, ğ‘£_

_ğ‘§_ _ğ‘–ğ‘£_ â‰¤ _ğ‘_ _ğ‘–ğ‘£_ _[ğ‘—]_ [+] _[ ğ‘€]_ [(][1][ âˆ’] _[ğ‘¦]_ _[ğ‘—]_ [)] _[,]_ âˆ€ _ğ‘–, ğ‘£, ğ‘—_


_ğ‘§_ _ğ‘–ğ‘£_ â‰¥ _ğ‘_ _ğ‘–ğ‘£_ _[ğ‘—]_ [âˆ’][1] âˆ’ _ğ‘€_ (1 âˆ’ _ğ‘¦_ _ğ‘—_ ) _,_ âˆ€ _ğ‘–, ğ‘£, ğ‘—_

_ğ‘¤_ _ğ‘–ğ‘£_ _[ğ‘—]_ [â‰¥(] _[ğœ‰]_ _ğ‘–ğ‘£_ [+] _[ ğ‘]_ _ğ‘–ğ‘£_ _[ğ‘—]_ [)] _[ğ‘§]_ _[ğ‘–ğ‘£]_ [âˆ’] _[ğ‘€]_ [(][1][ âˆ’] _[ğ‘¦]_ _[ğ‘—]_ [)] _[,]_ âˆ€ _ğ‘–, ğ‘£, ğ‘—_

_ğ‘¦_ _ğ‘—_ âˆˆ{0 _,_ 1} _, ğ‘¤_ _ğ‘–ğ‘£_ _[ğ‘—]_ [â‰¥] [0] _[, ğœ‹]_ [â‰¥] [0] _[, ğœ†]_ _[ğ‘–ğ‘£]_ [â‰¥] [0] _[.]_


**4.5.** **Performance Guarantees on C-SAA & C-RO**



(16)



Câ€“SAA replaces the unknown cost distribution with Monte-Carlo samples generated by a learned contextual


oracle and minimizes the resulting empirical objective. Under standard regularity conditions, the SAA


objective is statistically consistent: its optimal value converges exponentially fast to the true optimum as _ğ‘_ 1


grows (Kleywegt et al. 2002, Shapiro et al. 2021). When the oracle is well-calibrated and _ğ‘_ 1 is large, Câ€“SAA


thus attains the smallest _expected_ cost. However, it remains sensitive to distributional misspecification and


finite-sample error, which can expose the solution to rare but severe tail events.


Câ€“RO mitigates this risk by optimizing the worst-case cost over a prescribed uncertainty set. Let a feasible


solution **z** satisfy max _**ğƒ**_ âˆˆU( **s** ) _ğ‘”_ ( **z** _, ğƒ_ ) â‰¤ _ğ‘¡._ For a discrete uncertainty set built from _ğ‘_ samples (C-RO-D), one


obtains with probability 1 âˆ’ _ğ›¿_ that


Pr [ï¿½] _ğ‘”_ ( **z** _,_ Ëœ **c** ) _> ğ‘¡_ [ï¿½] â‰¤ _ğœ–_


provided



_ğ‘_ â‰¥ 2|V||I| + [2][|][V] [||][I][|]




[||][I][|] 2

ln
_ğœ–_ ï¿½ _ğœ–_



_ğ›¿_



ï¿½



_ğœ–_



ï¿½ + [2] _ğœ–_




[2] _ğœ–_ [ln] ï¿½ 1 _ğ›¿_



samples are drawn (Calafiore and Campi 2006, Campi and Garatti 2008, Bertsimas et al. 2021). Although


this bound grows linearly in the dimension of the uncertainty |V||I|, it too can degrade under distributional


misspecification. Under a budgeted-interval uncertainty set (C-RO-B), the violation probability instead



satisfies



_ğµ_ [2]
Pr [ï¿½] _ğ‘”_ ( **z** _,_ Ëœ **c** ) _> ğ‘¡_ [ï¿½] â‰¤ exp âˆ’
ï¿½ 2 |V||I|



_,_
ï¿½



so that the budget parameter _ğµ_ directly controls the trade-off between average-case performance and robust

ness (Bertsimas and Sim 2004). This tunable flexibility makes Câ€“RO-B an attractive middle ground between


Câ€“SAA and Câ€“RO-D.


Extending these guarantees to bound worst-case regret or post-decision surprise under partial-feedback


settingsâ€”where counterfactual costs are unobservedâ€”remains an important direction for future work.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
16


**4.6.** **Application to the Omnichannel Multi-Courier CSOFP**


The CSO framework applies directly to CSOFP via the following identifications:


I â†¦â†’{ SKUs } _,_ V â†¦â†’K Ã— L _,_


_ğ‘§_ _ğ‘–ğ‘£_ â†¦â†’ _ğ‘§_ _ğ‘–ğ‘˜â„“_ _,_ **s** _ğ‘£_ â†¦â†’ **s** _ğ‘˜â„“_ _,_


**c** Ëœ = ( Ëœ _ğ‘_ _ğ‘£_ ) _ğ‘£_ âˆˆV â†¦â†’ **d** [Ëœ] = ( _ğ‘‘_ [Ëœ] _ğ‘˜â„“_ ) _ğ‘˜_ âˆˆK _,â„“_ âˆˆL _._ P _ğ‘£_ â†¦â†’ P _ğ‘˜â„“_ _._


Under the conditional independence assumption,



P( **d** | **s** ) =
ï¿½

_ğ‘˜_ âˆˆK


Hence CSOFP (Problem 6) can be rewritten as



P _ğ‘˜â„“_ ( _ğ‘‘_ _ğ‘˜â„“_ | **s** _ğ‘˜â„“_ ) _._

ï¿½

_â„“_ âˆˆL



min **z** âˆˆZ [E] **[d]** [Ëœ] [âˆ¼][Î ] _[ğ‘˜,â„“]_ [P] _[ğ‘˜â„“]_ [(] _[ğ‘‘]_ _[ğ‘˜â„“]_ [|] **[s]** _[ğ‘˜â„“]_ [)] [ [] _[ğ‘”]_ [(] **[z]** _[,]_ [ Ëœ] **[d]** [)]] _[.]_ (17)


To learn each marginal distribution P _ğ‘˜â„“_ ( _ğ‘‘_ _ğ‘˜â„“_ | **s** _ğ‘˜â„“_ ), the historical dataset is first partitioned into D _ğ‘˜â„“_ =

_ğ‘€_ _ğ‘˜â„“_
ï¿½( **s** _ğ‘˜â„“,ğ‘š_ _, ğ‘‘_ _ğ‘˜â„“,ğ‘š_ )ï¿½ _ğ‘š_ =1 _[.]_ [ This is followed by training a per-carrier model] [ M] _[ğ‘˜]_ [on the dataset] [ D] _[ğ‘˜]_ [=][ ï¿½] _â„“_ âˆˆL [D] _ğ‘˜â„“_ [.]


This per-carrier approach is a practical adaptation of the generic per-option framework from Section 4.2.


Rather than training a distinct model for each individual location-carrier pair (which can be inefficient


and suffer from data sparsity), the data is pooled to train a single, more robust model for each carrier.


This decomposition simplifies learning, allows the model to generalize to new locations, and was found to


outperform a single global model in preliminary experiments. The full contextual distribution oracle is then



assembled as M( **s** ) = [ï¿½] M _ğ‘˜_ ( **s** _ğ‘˜â„“_ ) [ï¿½]



_ğ‘˜_ âˆˆK _, â„“_ âˆˆL _[.]_



**4.6.1.** **Applying C-SAA and C-RO** Computing the expectation in E **d** Ëœ âˆ¼M( **s** ) ï¿½ _ğ‘”_ ( **z** _,_ **d** [Ëœ] )ï¿½ directly would

require either enumerating all _ğ¶_ [|K|Ã—|L|] deviation vectors or numerically integrating a continuous CDFâ€”both


computationally intractable. Instead, the two solution paradigms use the contextual distribution oracle M( **s** )


as follows:


  - C-SAA replaces the expectation by a sample average: draw _ğ‘_ 1 full-vector scenarios { **d** [Ëœ] _[ğ‘›]_ } âˆ¼M( **s** ) and


solve



1
min
**z** âˆˆZ _ğ‘_ 1



_ğ‘_ 1
âˆ‘ï¸ _ğ‘”_ [ï¿½] **z** _,_ **d** [Ëœ] _[ğ‘›]_ [ï¿½] _._

_ğ‘›_ =1




  - C-RO builds an uncertainty set from oracle outputsâ€”either the discrete scenario set { **d** [Ëœ] _[ğ‘›]_ } _ğ‘›_ âˆˆ[ _ğ‘_ ] or a


budgeted-interval set from marginal quantilesâ€”and then solves


min max
**z** âˆˆZ **d** âˆˆU( **s** ) _[ğ‘”]_ [(] **[z]** _[,]_ **[d]** [)] _[.]_


Both approaches avoid the exponential support growth while remaining agnostic to the internal structure


of M . A full C-RO-B reformulation is provided in the Appendix F.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
17

## **5. Learning the Contextual Distribution of Delivery Deviations for CSOFP**


Having defined in Section 4 a generic contextual distribution oracle M( **s** ), this section describes its concrete


implementation for CSOFP. It begins by selecting features to construct the covariate vector. Two classes


of machine learning methods are then proposed to estimate the contextual distribution of deviations: (1)


Probabilistic multi-class classification, which leverages the discrete support of deviations; and (2) Tree-based


quantile regression, which directly estimates the conditional CDF and avoids quantile crossing (Salari et al.


2022).


For simplicity, the carrier index _ğ‘˜_ is omitted in the notation, and the dataset for training the per-carrier


model is written as D = {( **s** _ğ‘š_ _, ğ‘‘_ _ğ‘š_ )} _ğ‘š_ âˆˆ[ _ğ‘€_ ] .


**5.1.** **Contextual Feature Selection**


Carefully selecting contextual features is crucial for constructing informed covariates for delivery deviation


predictions, as various stages in the order life cycle can contribute to deviations.


Candidate features fall into three categories:


1. _Order-level_ : This includes customer location, SKU weight and dimensions, SKU type, quantities,


release hour, release day, and planned lead time (i.e., the difference between the promised delivery date


and the order release time). These factors can influence deviations through logistical complexity, handling


requirements, and time-sensitive elements affecting the orderâ€™s processing and delivery schedule.


2. _Fulfillment center_ : This includes coordinates, location type, on-hand capacity, and on-hand inventory.


The geographical location and type of fulfillment center can affect the efficiency of order processing, while


capacity and inventory levels determine the speed and reliability of fulfilling orders.


3. _Carrier-related_ : This includes service level, promised transit time, shipping charges, and carrier zone.


These factors impact the carrier ability to meet delivery deadlines, with service level and transit times


directly affecting deviations, while shipping charges and zones reflect logistical challenges and potential


bottlenecks.


**5.2.** **Probabilistic Multi-Class Classification**


This discrete nature allows the contextual distribution learning problem to be framed as a multi-class


classification (MC-CLF) problem. Under MC-CLF, each class represents a possible delivery deviation value


in number of days, and the output class probabilities correspond directly to the probability mass function of


the discrete distribution. For a new sample with covariates vector **s**, let the conditional probability of class _ğ‘_


be _ğ‘_ _ğ‘_ ( **s** ) = P( _ğ‘‘_ = _ğœ‰_ _ğ‘_ | **s** ), with the corresponding predicted probability from MC-CLF denoted as Ë† _ğ‘_ _ğ‘_ ( **s** ) .


Multinomial logistic regression (MLR) and classification tree-based models are considered to solve MC

CLF. Specifically, MLR is a classic classifier that aims to estimate the class probabilities by maximizing the


_ğ¶_
log-likelihood function, the negative of the log loss function. The log loss is defined as âˆ’ [ï¿½] _ğ‘š_ _[ğ‘€]_ =1 ï¿½ _ğ‘_ =1 **[1]** [{] _[ğ‘‘]_ _[ğ‘š]_ [=]


_ğœ‰_ _ğ‘_ } log( Ë† _ğ‘_ _ğ‘_ ( **s** _ğ‘š_ )) _._ On the other hand, classification trees use a nonparametric approach that recursively


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
18


partitions the data into subsets based on feature values in a top-down manner, resulting in a tree-like model


of decisions.


Let R 1 _, . . .,_ R _ğ‘…_ be the regions partitioned by a classification tree. Classification tree estimates


Ë† ï¿½ _ğ‘Ÿğ‘…_ =1 **[1]** [{] **[s]** [ âˆˆR] _[ğ‘Ÿ]_ [} Â·] **[ 1]** [{] _[ğ‘‘]_ [=] _[ ğœ‰]_ _[ğ‘]_ [}]
_ğ‘_ _ğ‘_ ( **s** ) = ~~ï¿½~~ _ğ‘Ÿğ‘…_ =1 **[1]** [{] **[s]** [ âˆˆR] _[ğ‘Ÿ]_ [}] _,_ (18)


To enhance predictive power, ensemble learning methods such as bagging and gradient boosting are


employed, through the use of random forests (RF) and gradient boosted trees (GBT). The details for their


calculation of the class probabilities are available in Appendix G.


The performance of the MC-CLF models are evaluated by log loss and Brier score. The latter is defined


as the average squared error between predicted probabilities and actual outcomes [ï¿½] _ğ‘š_ _[ğ‘€]_ =1 ï¿½ _ğ¶ğ‘_ =1 [(] **[1]** [{] _[ğ‘‘]_ _[ğ‘š]_ [=]


_ğœ‰_ _ğ‘_ } Ë† _ğ‘_ _ğ‘_ ( **s** _ğ‘š_ )) [2] . For both metrics, lower values indicate better probabilistic prediction performance.


**5.2.1.** **Probability Calibration** Raw class-probability estimates Ë† _ğ‘_ _ğ‘_ ( **s** ) from classifiers often exhibit


mis-calibration: a predicted probability _ğ›¼_ does not correspond to an empirical frequency _ğ›¼_ (Niculescu-Mizil


and Caruana 2005). _Good calibration_ means that, over all samples with Ë† _ğ‘_ _ğ‘_ ( **s** ) = _ğ›¼_, the true fraction belonging


to class _ğ‘_ is approximately _ğ›¼_ . Formally, let _ğ‘“_ ( _ğ›¼_ ) = P [ï¿½] _ğ‘‘_ = _ğœ‰_ _ğ‘_ | Ë† _ğ‘_ _ğ‘_ ( **s** ) = _ğ›¼_ [ï¿½] be the calibration function. Perfect


calibration means _ğ‘“_ ( _ğ›¼_ ) = _ğ›¼_ for all _ğ›¼_ âˆˆ[0 _,_ 1] .


Isotonic regression (Zadrozny and Elkan 2002) learns a non-decreasing mapping _ğ‘”_ : [0 _,_ 1] â†’[0 _,_ 1] that


best aligns raw scores to observed frequencies, preserving the rank order of Ë† _ğ‘_ _ğ‘_ . Given a calibration set

D _ğ‘ğ‘ğ‘™_ = {( Ë† _ğ‘_ _ğ‘_ ( **s** _ğ‘š_ ) _, ğ‘¦_ _ğ‘,ğ‘š_ )} _ğ‘š_ _[ğ‘€]_ = _[ğ‘ğ‘ğ‘™]_ 1 [with] _[ ğ‘¦]_ _[ğ‘,ğ‘š]_ [=] **[ 1]** [{] _[ğ‘‘]_ _[ğ‘š]_ [=] _[ ğœ‰]_ _[ğ‘]_ [}] [, isotonic regression solves]



min

_ğ‘”_



_ğ‘€_ _ğ‘ğ‘ğ‘™_
âˆ‘ï¸

_ğ‘š_ =1



2
ï¿½ _ğ‘¦_ _ğ‘,ğ‘š_ âˆ’ _ğ‘”_ ( Ë† _ğ‘_ _ğ‘_ ( **s** _ğ‘š_ ))ï¿½ s.t. _ğ‘”_ ( _ğ›¼_ ) â‰¤ _ğ‘”_ ( _ğ›¼_ [â€²] ) whenever _ğ›¼_ â‰¤ _ğ›¼_ [â€²] _._



The calibrated probabilities are Ëœ _ğ‘_ _ğ‘_ ( **s** ) = _ğ‘”_ ( Ë† _ğ‘_ _ğ‘_ ( **s** )) . By enforcing monotonicity, isotonic calibration ensures


that higher raw scores remain higher after mapping, and empirical frequencies within each score bin match


the calibrated values.


In this paper, a _ğ‘˜_ -fold cross-validation procedure is employed: for each fold _ğ‘–_, the classifier is trained on


its training split, raw scores are obtained on the held-out calibration split, and an isotonic regression model


_ğ‘”_ [(] _[ğ‘–]_ [)] is fit to those scores. On unseen test instance with covariates **s**, each foldâ€™s classifier and corresponding

_ğ‘”_ [(] _[ğ‘–]_ [)] yield calibrated probabilities Ëœ _ğ‘_ _ğ‘_ [(] _[ğ‘–]_ [)] [(] **[s]** [)] [, which are then averaged across all] _[ ğ‘˜]_ [folds to produce the final]

estimate Ëœ _ğ‘_ _ğ‘_ ( **s** ) = _ğ‘˜_ [1] ï¿½ _ğ‘–ğ‘˜_ =1 _[ğ‘]_ [Ëœ] _ğ‘_ [(] _[ğ‘–]_ [)] [(] **[s]** [)] _[ .]_ [ Since per-class calibration does not guarantee the final probabilities will]

sum to one, a normalization step is applied. The vector of calibrated class probabilities [ï¿½] _ğ‘_ Ëœ _ğ‘_ ( **s** ) [ï¿½] _[ğ¶]_ _ğ‘_ =1 [is divided]


by its sum to yield a valid multi-class probability distribution.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
19


**5.3.** **Tree-Based Quantile Regression**


Unlike multi-class classification methods that treat each deviation value as an unordered category, quantile


regression (QR) exploits the inherent ordering of deviations by framing the task as ordinal regression and


directly estimating the conditional cumulative distribution function (CDF) _ğ¹_ ( _ğ‘¢_ | **s** ) = P( _ğ‘‘_ â‰¤ _ğ‘¢_ | **s** ) .


Standard QR models minimizes, for each quantile level _ğ‘_, the pinball loss


_ğœŒ_ _ğ‘_ ( _ğ‘‘,_ _ğ‘‘_ [Ë†] ) = _ğ‘_ max( _ğ‘‘_ âˆ’ _ğ‘‘,_ [Ë†] 0) + (1 âˆ’ _ğ‘_ ) max( _ğ‘‘_ [Ë†] âˆ’ _ğ‘‘,_ 0) _,_ (19)


where _ğ‘‘_ [Ë†] denotes the modelâ€™s predicted _ğ‘_ -th quantile. Collecting these quantile estimates across _ğ‘_ yields


a stepwise approximation of the CDF. However, estimating each quantile independently can violate the


ordering _ğ‘‘_ [Ë†] ( _ğ‘_ 1 ) â‰¤ _ğ‘‘_ [Ë†] ( _ğ‘_ 2 ) for _ğ‘_ 1 _< ğ‘_ 2, resulting in a non-monotonicâ€”and thus invalidâ€”CDF.


Tree-based QR methodsâ€”namely regression trees extended to CDF estimation, and their ensemble


version, quantile random forests (QRF) (Meinshausen and Ridgeway 2006)â€”avoid this â€œquantile crossingâ€


problem by extracting quantiles from the empirical distribution of training sample in each leaf region.


A regression tree partitions the covariate space into disjoint regions to minimize mean squared error


(MSE). Although regression trees are often used for point forecasts (e.g., predicting the mean response in


each leaf), they can be adapted for distributional forecasting by preserving all observations within each


partitioned region. For a new sample with covariates **s**, let R( **s** ) be the leaf region into which **s** falls. The


conditional CDF of the deviation can then be approximated by the empirical distribution of the training


samples in that leaf:



_ğ¹_ Ë† ( _ğ‘¢_ | **s** ) =



_ğ‘€_
âˆ‘ï¸

_ğ‘š_ =1



**1** { **s** _ğ‘š_ âˆˆR ( **s** )}
|{ _ğ‘—_ : **s** _ğ‘—_ âˆˆR( **s** )}| **[1]** [{] _[ğ‘‘]_ _[ğ‘š]_ [â‰¤] _[ğ‘¢]_ [}] _[.]_ (20)



A subsequent kernel density estimation applied to { _ğ‘‘_ _ğ‘š_ : **s** _ğ‘š_ âˆˆR( **s** )} can further smooth this step-function


CDF (Salari et al. 2022).


QRF extends this approach by pooling the leaf-level samples across an ensemble of _ğ‘‡_ trees. For each tree


_ğ‘¡_, let R [(] _[ğ‘¡]_ [)] ( **s** ) be leaf region containing **s** _._ The QRF estimate of the conditional CDF is



_ğ‘€_
âˆ‘ï¸

_ğ‘š_ =1



_ğ¹_ Ë† ( _ğ‘¢_ | **s** ) = [1]

_ğ‘‡_



_ğ‘‡_
âˆ‘ï¸

_ğ‘¡_ =1



**1** { **s** _ğ‘š_ âˆˆR [(] _[ğ‘¡]_ [)] ( **s** )}
(21)
|{ _ğ‘—_ : **s** _ğ‘—_ âˆˆR [(] _[ğ‘¡]_ [)] ( **s** )}| **[1]** [{] _[ğ‘‘]_ _[ğ‘š]_ [â‰¤] _[ğ‘¢]_ [}] _[.]_



Because this procedure pools ordered observations directly, it naturally preserves the ordinal support and


never produces crossing quantiles.


To measure the distributional forecasting performance, the paper uses two metricsâ€”the Continuous


Ranked Probability Score (CRPS) and pinball loss. CRPS evaluates the closeness of the estimated CDF _ğ¹_ [Ë†]


given covariates **s** to the observed ground truth value _ğ‘‘_


âˆ
CRPS ( _ğ¹, ğ‘‘,_ [Ë†] **s** ) = ( _ğ¹_ [Ë†] ( _ğ‘¢_ | **s** ) âˆ’ **1** { _ğ‘¢_ â‰¥ _ğ‘‘_ }) [2] _ğ‘‘ğ‘¢._ (22)
âˆ« âˆ’âˆ


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
20


Let _ğœ‰_ and _ğœ‰_ [â€²] be two independent random variables with distribution _ğ¹_ [Ë†] ( _ğ‘¢_ | **s** ) . The CRPS can alternatively be


expressed as

CRPS ( _ğ¹, ğ‘‘,_ [Ë†] **s** ) = E(| _ğœ‰_ âˆ’ _ğ‘‘_ |) âˆ’ [1] (23)

2 [E][(|] _[ğœ‰]_ [âˆ’] _[ğœ‰]_ [â€²] [|)] _[.]_


This equation allows for an approximation of CRPS by sampling from _ğ¹_ [Ë†] ( _ğ‘¢_ | **s** ) . Pinball loss measures the


accuracy of quantile predictions by penalizing errors asymmetrically, depending on whether the predictions


are overestimates or underestimates.

## **6. Case Study**


This section presents computational results that demonstrate the potential of the proposed CSO framework


when evaluated on real-world industrial instances.


**6.1.** **Data Overview**


The industrial partner provides a month-long dataset in 2023, covering more than 1 million online orders for


home delivery and over 20,000 unique SKUs. Each order can be sourced from roughly 250 to 1,000 possible


fulfillment centers across the companyâ€™s network and shipped via one of 10 to 30 distinct carriers.


The target variable in the machine learning problem, delivery deviation, is defined as the difference


between the actual delivered date and the promised delivery date. To enhance the quality of the analysis,


order lines with extreme deviations were excludedâ€”specifically, those with absolute values greater than 10


days. Such outliers often reflect exceptional circumstances, including returns to sender, lost shipments, or


atypical business orders, which can introduce noise and bias into the model.


**6.2.** **Evaluation of Contextual Distributional Learning of Delivery Deviations**


This section evaluates the contextual distributional learning models presented in Section 5 for the case study.


**6.2.1.** **Machine Learning Model Settings** For the evaluation of the learning models, the dataset


was partitioned into a training set comprising orders from the first three weeks (approximately 1.3 million


order lines) and a test set consisting of orders from the final week (approximately 0.4 million order lines).


For multi-SKU orders, features were aggregated by retaining only those of the SKU with the highest


shipping charge and quantity. The MC-CLF models were implemented using scikit-learn (Pedregosa et al.


2011) and CatBoost (Prokhorenkova et al. 2018), with probability calibration applied to the best-performing


uncalibrated models based on cross-validated metrics. Quantile regression models, including regression tree


and QRF, were implemented via the quantile-forest package (Johnson 2024). All hyperparameters were tuned


using three-fold cross-validation in Optuna (Akiba et al. 2019): MC-CLF models were tuned to minimize


log loss, whereas quantile regression models were tuned to minimize CRPS.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
21


**6.2.2.** **Learning Performance Analysis** In Table 1, two standard metricsâ€”log loss and Brier


scoreâ€”are reported to measure the accuracy of probabilistic predictions for each tuned MC-CLF model


on the test set. Calibration yields a clear improvement: the calibrated classifier achieves the lowest log loss


(0.965) and Brier score (0.031), down from 1.050 and 0.034 for the uncalibrated gradient-boosted tree


(GBT-CLF), and substantially outperforming both the random-forest classifier (RF-CLF; 1.593, 0.054) and


the simpler baselines (MLR and classification tree).


Figure 3 presents the joint predicted distributions of (a) the calibrated-CLF, (b) the QRF, and (c) the


discretized regression tree, each plotted against the true empirical distribution for orders fulfilled by a


representative carrier. The calibrated-CLF closely reproduces the empirical mass at zero deviation (on-time


deliveries) and tightly follows the tails corresponding to early and late deliveries. The QRF exhibits slightly


greater discrepancies, particularly in the majority classes (-1 to 1), while the discretized regression tree


shows the largest misalignment from the empirical distribution.


**Table 1** **Out-of-Sample Average Log Loss and Brier Score Across All Carriers.**


Model MLR Classification Tree RF-CLF GBT-CLF Calibrated-CLF


Log loss 1.950 2.242 1.593 1.050 **0.965**
Brier score 0.073 0.072 0.054 0.034 **0.031**


**(a)** Calibrated-CLF **(b)** QRF **(c)** Regression Tree (discretized)


**Figure 3** **Out-of-Sample Comparison of the Joint Predicted Distribution and True Empirical Distribution for**


**an Example Carrier.**


Table 2 reports pinball losses at selected quantiles and CRPS values for the tuned quantile regression and


calibrated-CLF models. CRPS was approximated by drawing 1,000 samples to compute Equation (23). The


calibrated-CLF model exhibit higher pinball losses than the two quantile regression models, reflecting its


inherently discrete output, but nonetheless achieves the lowest CRPS overall, even though it was not directly


tuned for this metric. This superior CRPS performance likely results from calibration producing sharper


probability estimates, especially for the majority deviation classes.


Additionally, Figure 4 displays the 95% prediction intervals created by the three contextual distribution


learning methods for an example carrier. The visualization aligns with the pinball loss results, showing that


QRF generally provides the narrowest interval widths. While the intervals generated by calibrated-CLF cover


most of the observed values, their coverage is less effective at the two extremes compared to the two QR


methods. The inferior performance of calibrated-CLF at extreme quantiles is likely due to the discretization


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
22


of the output space, which limits precision, and the cumulative probability method, which can cause jumps


when selecting quantiles. In contrast, regression tree and QRF provide finer-grained predictions, leading to


more accurate and narrower intervals at the extremes.


In summary, MC-CLF models excel at providing distributional forecasts, whereas QR models are better


suited to generating prediction intervals on this dataset. Since QRF benefits from ensembling multiple


regression trees to reduce variance and improve accuracy and consistently outperform a single regression


tree, only QRF is kept for QR in the subsequent CSO evaluations.


**Table 2** **Out-of-Sample Average Pinball Loss and CRPS Across All Carriers.**


Pinball Loss CRPS

Model _ğ‘_ 0 _._ 025 _ğ‘_ 0 _._ 05 _ğ‘_ 0 _._ 5 _ğ‘_ 0 _._ 95 _ğ‘_ 0 _._ 975


Calibrated-CLF 0.199 0.198 0.676 0.526 0.304 **0.386**

QRF **0.033 0.057 0.263 0.143** 0.096 0.402
Regression Tree 0.064 0.109 0.302 0.147 **0.093** 0.515


**(a)** Calibrated-CLF Prediction Intervals **(b)** QRF Prediction Intervals **(c)** Regression Tree Prediction Intervals


**Figure 4** **Sorted Observed Deviation Values versus 95% Prediction Intervals for an Example Carrier on**


**Out-of-Sample Data.**


**6.3.** **Baseline Models**


To compare with the proposed contextual optimization models, four baseline order-fulfillment algorithms


are introduced below.


1. _Pure Cost-Driven Greedy Heuristic (Greedy)_ : Mimics the industrial partnerâ€™s fulfillment optimization


engine by selecting, for each unit of an SKU, the carrierâ€“location pair that minimizes the fulfillment cost.

Formally, for each order it solves min **z** âˆˆZ { [ï¿½] _ğ‘–,ğ‘˜,â„“_ [(] _[ğ‘]_ _â„“_ _[ğ‘“ğ‘–ğ‘¥ğ‘’ğ‘‘]_ + _ğ‘_ _ğ‘–ğ‘˜â„“_ _[ğ‘ â„ğ‘–ğ‘]_ [)] _[ğ‘§]_ _[ğ‘–ğ‘˜â„“]_ [}] _[.]_


2. _Empirical-SAA_ : Follows the SAA framework of Section 4.3, except that each deviation sample is drawn


from the overall empirical distribution _ğ‘ƒ_ _[ğ¸]_ of the training set, without using any contextual information. For



each _ğ‘›_ âˆˆ[ _ğ‘_ 1 ] and every ( _ğ‘˜,â„“_ ) âˆˆK Ã— L, _ğœ‰_ _ğ‘˜â„“_ _[ğ‘›]_ [âˆ¼] _[ğ‘ƒ]_ _[ğ¸]_ _[,][ ğƒ]_ _[ğ‘›]_ [=][ ï¿½] _[ğœ‰]_ _ğ‘˜â„“_ _[ğ‘›]_ ï¿½

min _**ğ’›**_ âˆˆZ _ğ‘_ 1 1 ï¿½ _ğ‘›ğ‘_ = 1 1 _[ğ‘”]_ [ï¿½] _[ğ’›][,][ ğƒ]_ _[ğ‘›]_ [ï¿½] _[.]_



_ğ‘˜_ âˆˆK _, â„“_ âˆˆL _[.]_ [ The empirical SAA problem is]



3. _C-Empirical-SAA_ : A slightly smarter SAA baseline that maintains separate empirical distributions _ğ‘ƒ_ _ğ‘˜_ _[ğ¸]_
for each carrier. For each _ğ‘›_ and ( _ğ‘˜,â„“_ ), _ğœ‰_ _ğ‘˜â„“_ _[ğ‘›]_ [âˆ¼] _[ğ‘ƒ]_ _ğ‘˜_ _[ğ¸]_ _[,][ ğƒ]_ _[ğ‘›]_ [=][ ï¿½] _[ğœ‰]_ _ğ‘˜â„“_ _[ğ‘›]_ ï¿½ _ğ‘˜_ âˆˆK _, â„“_ âˆˆL _[,]_ [ and it solves the same SAA problem]


as above.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
23


4. _Point Predictâ€“Thenâ€“Optimize (PTO)_ : Trains per-carrier regression models _â„_ _ğ‘˜_ (Â·) to estimate the condi

tional mean deviations for each ( _ğ‘˜,â„“_ ) âˆˆK Ã—L, producing the point-prediction vector **d** [Ë†] = { _â„_ _ğ‘˜_ ( **s** _ğ‘˜â„“_ )} _ğ‘˜_ âˆˆK _,â„“_ âˆˆL .


It then solves the deterministic problem min _**ğ’›**_ âˆˆZ _ğ‘”_ [ï¿½] _ğ’›,_ **d** [Ë†] [ï¿½] _._


This method is effective only if the objective function _ğ‘”_ ( **z** _,_ **d** [Ëœ] ) is linear in **d** [Ëœ], in which case estimating


the conditional distribution simplifies to estimating the conditional mean. This is because, by linearity


of expectation, E **d** Ëœ âˆ¼P( **d** | **s** ) [ _ğ‘”_ ( **z** _ğ‘œ_ _,_ **d** [Ëœ] )] = _ğ‘”_ ( **z** _,_ E **d** Ëœ âˆ¼P( **d** | **s** ) [ **d** [Ëœ] ]) . However, _ğ‘”_ ( _ğ’›,_ **d** [Ëœ] ) is nonlinear due to asymmetric


penalty costs of the deviations, hence replacing the distribution by its mean may bias the solution. For each


carrier, the regression model with the lowest cross-validated mean squared error is selected (see Appendix


H for details).


**6.4.** **Experimental Setting**


This section outlines the computational environment, simulation framework, and parameter configurations


used in the experiments.


**6.4.1.** **Implementation Environment** The optimization models in this study were implemented in


Python 3.9 using Gurobi 11.0.0, with eight threads allocated to each order instance. A termination criterion


of a 1% MIP gap or a 5-minute time limit was applied. All experiments were conducted on a server equipped


with dual-socket Intel Xeon Gold 6226 CPUs, each featuring 24 cores running at 2.7 GHz.


**6.4.2.** **Simulation Framework** One of the difficulties in this application is that the ground truth is


not available for options that were not selected. To overcome this limitation, a simulation environment


was built to generate synthetic â€œground truthâ€ when an algorithm selects an option. Specifically, delivery


deviations were drawn from a multinomial distribution, with probabilities estimated by fitting a fine-tuned,


calibrated multi-class classification model based on orders from the last week of the dataset (testing period).


Obviously, this data was not accessible to the algorithm and only used by the simulator to replicate real

world conditions. The training and calibration procedures of the simulator closely followed the methodology


outlined in Section 5.2. An evaluation of the simulator is provided in Appendix J.


For the following experiments, as mentioned in Section 6.2, all ML models were trained on order data from


the first three weeks. Evaluation was conducted on 5,000 multi-item orders, randomly sampled from the final


week. To account for variability, solution metrics were computed across 50 random realizations. _All reported_


_metrics were normalized by setting the Greedy baseline to 1 for each random seed; true performance values_


_were omitted to due to data confidentiality._


**6.4.3.** **Model Names and Parameters** In the following, the C-SAA problems using samples from


the contextual distribution estimates provided by the MC-CLF and QRF models are referred to as C-SAA

CLF and C-SAA-QRF, respectively. Similarly, the C-RO problems are referred to as C-RO- _{_ B,D _}_ -CLF and


C-RO- _{_ B,D _}_ -QRF, respectively.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
24


By default, a constant _ğ›½_ _ğ‘˜_ = 0 _._ 5 consolidation discount factor for all _ğ‘˜_ âˆˆK was considered. The default


penalty for early delivery _ğ›¾_ [âˆ’] was 0 _._ 1 and that for late delivery _ğ›¾_ [+] was 10 . For SAA-based methods, the


default was to have _ğ‘„_ = 20 independent replications each with a sample size of _ğ‘_ 1 = 30 . The obtained


solutions were then evaluated with a default sample size of _ğ‘_ 2 = 300 . The default sample size used for


C-RO-D was _ğ‘_ = 200 . As for C-RO-B, a default of 95% interval was considered. Moreover, a scaling factor


_ğœ‚_ âˆˆ[0 _,_ 1] (default of 0.5) determined the uncertainty budget in C-RO-B, defined as _ğµ_ = _ğœ‚_ |K| |L| _._


**6.5.** **Overall Results**


Table 3 reports the normalized average and worst-case objective values across 50 random seeds and all order


instances. Based on these results, the following observations are drawn.


_Average Performance_ The C-SAA variants and C-RO-B-CLF method lead to more reduction in the


expected objective than other methods. C-SAA-CLF achieves the greatest reduction, with a normalized


mean of 0.820 Â± 0.003 (â€“18.0% versus Greedy), followed by C-SAA-QRF at 0.844 Â± 0.003 (â€“15.6%) and


C-RO-B-CLF at 0.842 Â± 0.003 (â€“15.8%). By comparison, Empirical-SAA (0.962 Â± 0.002) and PTO (0.878


Â± 0.003) offer smaller improvements, and C-Empirical-SAA (0.870 Â± 0.003) performs only marginally


better than PTO.


_Worst-Case Performance_ The C-RO-D methods deliver the strongest guarantees under the worst sim

ulated outcome: C-RO-D-CLF attains 0.779 (â€“22.1%), C-RO-D-QRF 0.787 (â€“21.3%), and C-RO-B-CLF


0.811 (â€“18.9%). These three methods uniformly dominate the baseline and other approaches in the worst-case


metric.


Overall, the C-SAA approaches excel in minimizing the expected objective, while the C-RO-D variants


excel in worst-case robustness. Notably, C-RO-B-CLF strikes a strong balance between average efficiency


and tail-risk protection.


**Table 3** **Average and Worst-Case Realized Objective Values Across**


**Different Order Fulfillment Methods.**


Method Average Objective (95% CI) Worst-Case Objective


Greedy 1.000 Â± 0.000 1.000
PTO 0.878 Â± 0.003 0.919
Empirical-SAA 0.962 Â± 0.002 1.049
C-Empirical-SAA 0.870 Â± 0.003 0.896
C-SAA-CLF **0.820** Â± **0.003** 0.823

C-SAA-QRF **0.844** Â± **0.003** 0.842
C-RO-B-CLF **0.842** Â± **0.003** **0.811**

C-RO-B-QRF 0.861 Â± 0.003 0.824
C-RO-D-CLF 0.928 Â± 0.003 **0.779**

C-RO-D-QRF 0.914 Â± 0.003 **0.787**


Note: Top 3 methods for each metric are highlighted in bold.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
25


**6.6.** **Effectiveness of C-SAA**


This section further compares the performance of the C-SAA methods with the two Empirical-SAA baselines


and the PTO.


**6.6.1.** **Value of Contextual Information** To facilitate a closer examination of the performance of


the SAA-based models, Figure 5 shows the impact of varying sample sizes ( _ğ‘_ 1 ). On the one hand, larger


sample sizes should provide a more accurate approximation of the expected value in Problem (6), assuming


the delivery deviation distributions were well-estimated. On the other hand, it is important to maintain a


reasonably small sample size to ensure computational efficiency. For both C-SAA methods, the effect of


increasing sample sizes is obvious. The average objectives are reduced from 0.85 to 0.82 for C-SAA-CLF


and 0.88 to 0.84 for C-SAA-QRF, indicating their increasing alignment with the true risk-neutral objective


function. This improvement is particularly evident in their enhanced effectiveness at avoiding cumulative


lateness, defined to be the total number of late delivery days across all units in the orders. The cumulative


lateness decreases by 14% for C-SAA-CLF and by 12% for C-SAA-QRF.


In contrast, both Empirical-SAA and C-Empirical-SAA struggles to improve there performance in both the


average realized objective value and the cumulative lateness as the sample size grows. This is because relying


solely on the empirical distribution fails to capture the variability in delivery deviation distributions, which


may depend on contextual information specific to each order. A biased distributional forecasts thus guide


the model wrongly to create solutions with inferior quality. Based on these observations, both contextual


distributional forecasting methods proposed in the paper are successful in this application, demonstrating


a stronger performance compared to using empirical distribution for delivery deviation forecasting. In


summary, the value of contextual information is particularly important in order fulfillment decision-making,


where the uncertainty of delivery deviation can vary drastically across different states of the environment.


**(a)** Performance in Average Realized Objective Value. **(b)** Performance in Cumulative Lateness.


**Figure 5** **C-SAA vs. Empirical SAA Across Different Sample Sizes.**


**6.6.2.** **Value of Distributional Forecasts** This section examines the advantage of employing dis

tributional forecasting models over the simpler and more common point prediction model within the CSO


framework. As supported by theory, simply using the conditional mean estimate of deviations to replace the


expected value in CSOFP can introduce bias when approximating the true objective value, thus degrading


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
26


solution quality. Figure 6 confirms that, under changing _ğ›¾_ [+], CSO methods with distributional estimator


(C-SAA-CLF and C-SAA-QRF) consistently outperform PTO in both average realized objective value (Fig

ure 6a) and cumulative lateness (Figure 6b). In fact, the performance differences become more pronounced


as late delivery penalty ( _ğ›¾_ [+] ) increases.


When _ğ›¾_ [+] raises from 2.5 to 40, PTO achieves only a 7% reduction in cumulative lateness, whereas C

SAA-CLF and C-SAA-QRF realize reductions of approximately 22% and 20%, respectively. These results


demonstrate that distributional forecasting not only enables lower overall lateness but also leverages higher


penalties more effectively, yielding a sharper decline in average objective and making C-SAA particularly


well suited to settings where delivery timeliness is critical.


**(a)** Performance in Average Realized Objective Value. **(b)** Performance in Cumulative Lateness.


**Figure 6** **C-SAA vs. PTO Across Different Late Delivery Penalties.**


**6.7.** **Cost of Robustness**


To quantify the trade-off between robustness and efficiency, C-RO-B-CLF and C-RO-D-CLF were compared


with C-SAA-CLF as the late-delivery penalty ( _ğ›¾_ [+] ) increases (Figure 7).


As depicted in Figure 7a, at _ğ›¾_ [+] = 2.5, average objectives are approximately 0.92 for C-SAA-CLF, 0.95 for


C-RO-B-CLF, and 1.00 for C-RO-D-CLF. As _ğ›¾_ [+] rises to 40, these values decline in parallelâ€”C-SAA-CLF


to 0.63, C-RO-B-CLF to 0.67, and C-RO-D-CLF to 0.73. Throughout this range, C-SAA-CLF consistently


achieves the lowest average objective, followed by C-RO-B-CLF and then C-RO-D-CLF.


Worst-case objectives (Figure 7b) underscore the robustness of the C-RO methods: C-RO-D-CLF consis

tently yields the strongest tail protection, dropping from 0.88 at _ğ›¾_ [+] = 2.5 to 0.72 at _ğ›¾_ [+] = 40. C-RO-B-CLF


falls from 0.885 to 0.775, while C-SAA-CLF declines more steeply from 0.925 to 0.73. Notably, at _ğ›¾_ [+] = 40,


C-SAA-CLF nearly matches C-RO-D-CLF, demonstrating that C-SAA can approach robust performance


under extreme penalty scenarios.


This robustness manifests in cumulative lateness (Figure 7c). Both C-RO variants tightly control lateness


with minimal sensitivity to _ğ›¾_ [+], whereas C-SAA-CLFâ€™s lateness drops substantially from 0.67 at _ğ›¾_ [+] = 2.5 to


0.46 at _ğ›¾_ [+] = 40. These robustness gains incur higher expected fulfillment costs (Figure 7d). C-RO-D-CLFâ€™s


average cost increases from 1.07 to 1.20, and C-RO-B-CLFâ€™s from 1.01 to 1.05, and C-SAA-CLF from


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
27


0.96 to 1.05. Thus, while all methods incur higher costs under stricter penalties, C-RO-B-CLF exhibits the


smallest relative cost increase, C-SAA-CLF and C-RO-D-CLF have more aggressive increases in costs due


to more conservative decisions.


A final strategic consideration lies in selecting _ğ›¾_ [+] to reflect firm priorities. Lower _ğ›¾_ [+] emphasizes immediate


cost savingsâ€”maximizing short-term profitsâ€”whereas higher _ğ›¾_ [+] prioritizes on-time delivery, fostering


customer satisfaction, loyalty, and long-term value. The CSOFP framework encodes this trade-off directly


via _ğ›¾_ [+] ; robust formulations (C-RO-B-CLF and C-RO-D-CLF) further reduce the need for precise _ğ›¾_ [+] tuning


by delivering stable, worst-case performance across penalty levels, while C-SAA-CLF can leverage high _ğ›¾_ [+]


most aggressively when strict timeliness is paramount.


**(a)** Performance in Average Realized Objective Value. **(b)** Performance in Worst-Case Realized Objective Value.


**(c)** Performance in Cumulative Lateness. **(d)** Performance in Fulfillment costs.


**Figure 7** **C-RO vs. C-SAA Across Different Late Delivery Penalties.**


**6.7.1.** **Flexibility of C-RO-B** The C-RO models effectively hedge against worst-case delivery devi

ations and potential misspecifications in the prediction models. However, this robustness incurs more con

servative decisions and higher fulfillment costs. The C-RO-B variants retain the distribution-free guarantees


while introducing two tuning parametersâ€”prediction-interval coverage and robust uncertainty budgetâ€”that


directly control conservativeness. Lower coverage levels and smaller budgets yield less conservative, more


cost-efficient solutions (at the expense of risk protection), whereas higher values emphasize hedging against


extreme deviations by sacrificing average performance.


Figures 8 and 9 summarize how these parameters affect solution quality under both C-RO-B-CLF and


C-RO-B-QRF. As the prediction interval coverage increases from 70% to 90%. In Figure 8a, increasing cov

erage from 70% to 90% reduces the average objective to about 0.84 (C-RO-B-CLF) and 0.86 (C-RO-B-QRF),


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
28


an approximately 4% improvement relative to 70% coverage. This is consistent with the concurrent decline in


cumulative lateness shown in Figure 8c. However, pushing coverage beyond 95% reverses this trend: at 99%


coverage the average objective rises sharply due to the cost of extreme conservatism and, for C-RO-B-CLF,


degraded prediction accuracy (reflected in a spike in lateness). By contrast, C-RO-B-QRF continues to


reduce lateness at 99%, illustrating its superior tail modeling. In terms of worst-case performance (Figure


8b), both methods improve with coverage, but C-RO-B-CLF plateaus after 95%, whereas C-RO-B-QRF


continues to improve at 99%.


The effect of the robust budget, controlled by the scaling factor _ğœ‚_, appears in Figure 9. Increasing _ğœ‚_


from zero to 0.01 leads to a steep drop in the average objective for both methods (Figure 9a). Both method


reach their minimum values at _ğœ‚_ = 0 _._ 01 . At the same time, the worst-case objective follows a similar pattern


(Figure 9b): it falls sharply up to _ğœ‚_ = 0 _._ 1, then edges back up for both methods as the budget grows. This trend


is also seen in cumulative lateness, which drops dramatically until _ğœ‚_ = 0 _._ 1 and then levels off (Figure 9c).


Together, these trends show that moderate budgets capture most of the gains in both average and worst case


performance, while further increases deliver diminishing returns.


**(a)** Performance in Avg. Obj. **(b)** Performance in Worst-Case Obj. **(c)** Performance in Cumulative Lateness.


**Figure 8** **Performance of C-RO-B Across Different Prediction Interval Coverages.**


**(a)** Performance in Avg. Obj. **(b)** Performance in Worst-Case Obj. **(c)** Performance in Cumulative Lateness.


**Figure 9** **Performance of C-RO-B Across Different Robust Uncertainty Budgets.**


**6.8.** **Impact of Consolidation Factor**


This section provides a discussion on the impact of item consolidation. CSOFP relies on the coefficients _ğ›½_ _ğ‘˜_


to control the incentive to batch items. The industrial partner does not know the exact percentage of discount


to be offered for item consolidation, which may depend on a variety of convoluted factors. Therefore, this


section performs sensitivity analysis on a range of possible discount factors (from 0.1 to 0.7).


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
29


Figure 10 compares the performance of three leading methodsâ€”C-SAA-CLF, C-RO-B-CLF, and C-RO

D-CLF across average and worst-case realized objective, fulfillment cost, and consolidation level. Consoli

dation level is defined as the percentage of units batched (sourced and shipped by the same locationâ€“carrier


pair) in each order.


As shown in Figure 10a, deeper discounts lead each method to exploit batching incentives more aggres

sively. C-SAA-CLF consistently attains the lowest average objective across all discount factors, declining


from approximately 0.875 at _ğ›½_ = 0.1 to about 0.785 at _ğ›½_ = 0.7. C-RO-B-CLF follows closely, from 0.895


down to 0.805, while C-RO-D-CLF remains the most conservative, decreasing from 0.955 to 0.905.


The worst-case objective exhibits a more differentiating pattern (Figure 10a). Both C-RO-D-CLF and


C-RO-B-CLF are less susceptible to change in the discount, whereas C-SAA-CLF starts at 0.842 and falls


to 0.802 under high discounts.


As expected, all three methods exhibit lower average objective values due to lower fulfillment costs as


the discount factor increases (see Figure 10c). This aligns with the intuition that higher discounts encourage


more cost-efficient fulfillment strategies. The relative decrease in fulfillment costs across the methods can


be attributed to their higher consolidation levels as the discount factor increases, as shown in Figure 10d.


Notably, C-SAA-CLF responds most sharply, with its consolidation rate rising the most rapidly as the


discount grows, which is consistent with its pronounced improvement in worst-case objective performance.


**(a)** Performance in Average Realized Objective Value. **(b)** Performance in Worst-Case Realized Objective Value.


**(c)** Performance in Fulfillment Costs. **(d)** Performance in Consolidation Level.


**Figure 10** **Performance of CSO Methods Across Different Consolidation Discount Factors.**


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
30


**6.9.** **Perturbation Analysis under Varying Simulation Environments**


A critical challenge in any simulation-based evaluation is that the simulator itself is an imperfect model of the


real-world data-generating process. This is particularly true in this application, where the purely observational


nature of the historical data, and the resulting lack of counterfactual outcomes, make it impossible to construct


a perfect, clairvoyant simulator. Therefore, to rigorously assess the stability of the proposed solutions, this


section performs a stress test designed to probe the frameworkâ€™s performance under a misspecified ground


truth. This analysis is conducted by introducing systematic perturbations to the simulated delivery time


deviation distributions, representing moderate to adversarial divergences from the test data. Specifically,


two types of perturbations are considered: random uniform noise and a delay-specific bias applied to the


simulation probability distributions. Together, these tests provide critical insight into the methodsâ€™ stability


under real-world distributional shifts and their robustness to the inevitable simulator-reality mismatch.


_Random Uniform Noise Perturbation_ Let the original simulation distribution for each test instance


be denoted by _ğ‘ƒ_ _[ğ‘ ğ‘–ğ‘š]_ = { _ğ‘_ _ğ‘–_ } _[ğ¶]_ _ğ‘–_ =1 [. For each class] _[ ğ‘–]_ [âˆˆ[] _[ğ¶]_ []] [, a random noise term] _[ ğ›¿]_ _[ğ‘–]_ [âˆ¼U(âˆ’] _[ğœ–, ğœ–]_ [)] [ is added to the]


probability _ğ‘_ _ğ‘–_, resulting in: Ëœ _ğ‘_ _ğ‘–_ = _ğ‘_ _ğ‘–_ + _ğ›¿_ _ğ‘–_ _._ Negative values are clipped: Ëœ _ğ‘_ _ğ‘–_ = max( Ëœ _ğ‘_ _ğ‘–_ _,_ 0), and the resulting


vector is normalized to form a valid probability distribution: Ëœ _ğ‘_ _ğ‘–_ = Ëœ _ğ‘_ _ğ‘–_ / [ï¿½] _ğ‘—_ _[ğ‘]_ [Ëœ] _ğ‘—_ [.]


Figure 11 reports the average and worst-case realized objectives as the noise level _ğœ–_ increases. In the


average case (Figure 11a), both C-RO variants degrade more gradually than C-SAA, with C-RO-B-CLF


becoming the top performer beyond _ğœ–_ = 10 . In the worst-case scenario (Figure 11b), while all methods


experience performance degrade, the ranking remains unchanged: C-RO-D achieves the lowest realized


objective, followed by C-RO-B, and then C-SAA. These results indicate the superior robustness of the C-RO


methods under uniform noise.


_Delay-Specific Bias Perturbation_ Define the set of late-delay classes _ğ¶_ late = { _ğ‘–_ : _ğœ‰_ _ğ‘–_ _>_ 0} . A multiplica

tive bias _ğœ‚_ is applied to those classes: Ëœ _ğ‘_ _ğ‘–_ = _ğ‘_ _ğ‘–_ - (1 + _ğœ‚_ ) _._ The probabilities for classes not in _ğ¶_ late remain


unchanged. The resulting vector is clipped to the interval [0 _,_ 1] : Ëœ _ğ‘_ _ğ‘–_ = max(min( Ëœ _ğ‘_ _ğ‘–_ _,_ 1) _,_ 0), followed by


normalization.


Figure 12 shows performance metrics for bias levels up to 250%. In the average case (Figure 12a), all CSO


methods demonstrate improved performance relative to the Greedy baseline, which deteriorates rapidly. This


trend is evidenced by the overall decrease in normalized objective values as the bias parameter _ğœ‚_ increases.


Notably, C-RO-B overtakes C-SAA once _ğœ‚_ exceeds 150%, highlighting its robustness under adversarial delay


distortions. In the worst-case objective (Figure 12b), C-RO-D consistently achieves the best performance,


followed by C-RO-B-CLF. Overall, the C-RO methods exhibit lower variability in performance compared


to C-SAA, indicating enhanced stability under adversarial delay conditions.


**6.10.** **Computational Scalability of the CSO Methods**


The computational scalability of the proposed framework was evaluated by measuring both the change


in computation time (model construction + solve time) and solution quality as instance size grows. Each


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
31


**(a)** Change in Average Objective. **(b)** Change in Worst-Case Objective.


**Figure 11** **Performance Across Different Random Uniform Noise Perturbations.**


**(a)** Change in Average Objective. **(b)** Change in Worst-Case Objective.


**Figure 12** **Performance Across Different Delay-Specific Bias Perturbations.**


CSOFP instance is characterized by the number of items |I| and the number of locationâ€“carrier pairs


(fulfillment options) |K|Ã—|L| . In practice, the eligibility constraint (Constraint (3)) is used to prune infeasible


locationâ€“carrier pairs in advance. Then, (K [â€²] _,_ L [â€²] ) = ï¿½( _ğ‘˜,â„“_ ) âˆˆK Ã— L ï¿½ï¿½ âˆƒ _ğ‘–_ âˆˆI : _ğ‘’_ _ğ‘–ğ‘˜â„“_ = 1ï¿½ yields the final set


of eligible fulfillment options and thus the effective problem size.


Figure 13a shows computation time as the number of eligible fulfillment options increases. Only the


MC-CLF variants of C-RO and C-SAA are displayed, since their QRF counterparts exhibit nearly identical


runtimes. All three methods achieve optimality on every instance within minutes, confirming their practical


applicability. In particular, C-RO-B solves most instances in under one second (never exceeding three


seconds), and C-RO-D solves most in under ten seconds.


These timing differences reflect each methodâ€™s formulation. Compared to the nominal problem, the robust


counterpart in C-RO-B introduces only continuous variables whose count grows linearly with |K [â€²] | and |L [â€²] | .


By contrast, C-RO-D adds _ğ‘_ extra constraints from sampling, and C-SAA requires solving _ğ‘„_ independent


problems whose objective function complexity scales with the sample size _ğ‘_ 1 . Parallel computation of the


_ğ‘„_ subproblems can further reduce C-SAAâ€™s runtime.


For completeness, a comparison of computation times against the baseline models is provided (see


Appendix K). The Greedy and PTO methods are computationally cheaper, solving most instances in fractions


of a second. However, the proposed CSO methods, particularly the highly-efficient C-RO-B, remain well


within practical time limits for real-world deployment (Figure 13a). The substantial improvements in solution


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
32


quality (Table 3) justify this modest increase in computational overhead, representing a favorable trade-off


between performance and speed.


Since single-item orders account for the majority of order volume, multi-item orders (what the methods


are designed for) can be routed to a dedicated fulfillment optimization engine without disrupting standard


operations. Under normal load, any of the three methods may be applied; under peak loadsâ€”such as holiday


surgesâ€”C-RO-B is recommended to preserve fast solve times while maintaining high solution quality.


Concurrent batches of orders can be processed in parallel when computational resources permit.


Figure 13b reports average and worst-case objective values for small ( â‰¤ 400 eligible options), medium


( â‰¤ 1000 eligible options), and large ( â‰¤ 3000 eligible options) instances. Average performance remains


uniformly high across all size categories, whereas worst-case deviations grow with instance size. Collectively,


these results demonstrate near-linear scalability in computation time, consistent high solution quality, and


robustness across problem sizes, providing empirical evidence of the frameworkâ€™s practical scalability.


**(a)** Change in the Computation Time vs. the Number of Eligible Fulfillment Options. **(b)** Objective Value by Instance Categories.


**Figure 13** **Computational Scalability Analysis.**


**6.11.** **Managerial and Operational Implications**


The proposed fulfillment framework offers actionable guidance for practitioners seeking to align fulfillment


strategies with demand variability, service-level requirements, and computational constraints. Depending on


the operating context, different methods are preferable. When demand is stable and the goal is to minimize


average fulfillment cost, C-SAA-CLF provides the most cost-effective solution. Under moderate runtime


constraints, C-RO-B-CLF offers a balanced trade-off between efficiency and robustness. In contrast, during


high-stakes periods such as holiday promotions or flash salesâ€”where the cost of service-level violations


is highâ€”C-RO-D-CLF and C-RO-B-QRF (with 99% coverage) are better suited to mitigate tail risks


and ensure reliability. This scenario-driven approach allows e-commerce platforms to dynamically adapt


fulfillment strategies to shifting conditions while leveraging a unified optimization infrastructure. As retailers


increasingly face variable demand patterns and rising customer expectations, the ability to flexibly match


fulfillment strategy to context becomes a key operational advantage.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
33


Empirical evaluations indicate that the proposed methods can reduce combined fulfillment cost and


delivery-timeliness penalties by an average of up to 18% per order under the default settings. To illustrate the


potential impact, consider a retailer operating at a scale comparable to the industrial partner, with per-order


costs ranging from $5 to $30 and monthly volumes of 0.1 to 1 million multi-item orders. Under these


scenarios, the corresponding annual savings could range from several million to tens of millions of dollars.


Moreover, this framework can be readily extended to single-item orders, which could yield further savings


with minimal incremental investment.

## **7. Conclusion**


This paper introduces a generic contextual stochastic optimization (CSO) framework for data-driven decision


making when only observational data, hence missing counterfactual costs, are available. The framework is


deliberately modular. First, any algorithm capable of returning a full predictive distribution can serve as


the _contextual distribution oracle_ . In the empirical study, calibrated multi-class classifiers and tree-based


quantile-regression forests were selected to capture the discrete, ordered nature of delivery-time deviations.


Second, the oracle feeds directly into two tractable optimization engines: (i) a _Contextual Sample-Average_


_Approximation_ (C-SAA) for risk-neutral objectives and (ii) a _Contextual Robust Optimization_ (C-RO)


formulation for risk-averse objectives. Because the learning and optimization layers communicate only


through the oracle, the template can be readily translated to other operations-management settings.


When applied to an omnichannel, multi-courier order-fulfillment problem, the CSO framework reduced


the combined costâ€“service objective by up 18% on average and up to 22% in the simulated worst case on an


industry-scale data set, implying annual savings from several to tens of millions of dollars. This framework


allows practitioners to tune robustnessâ€”raising it during promotional peaks and relaxing it in steadier


periodsâ€”while still exploiting item-consolidation discounts and heterogeneous carrier performance in the


dynamic e-commerce landscape.


While the paper delivers an end-to-end prototype with demonstrable impact, several avenues remain open:


  - Performance guarantees under partial feedback: Establish theoretical performance guarantees, such as


worst-case regret and post-decision surprise, for CSO methods under the partial-feedback setting. Linking


causal-inference techniques with SAA and RO theory can be a promising direction, thereby quantifying the


value of additional data when counterfactual costs remain unobserved.


  - Hybrid distributional forecasters: Develop distributional models that fuse the calibration strength of


classification with the sharp tails of quantile regression, yielding tighter and more informative uncertainty


sets.


  - End-to-end predict-then-prescribe learning for observational data: Incorporate downstream optimiza

tion loss directly into training, extending recent â€œintegrated predict-then-optimizeâ€ approaches (Qi et al.


2021, Elmachtoub and Grigas 2022) to settings where data are purely observational.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
34


  - Multi-period, inventory-aware CSO: Extend the framework to jointly optimize fulfillment, shipping,


and stocking over rolling horizons, capturing inventory replenishment spillovers and elevate the model from


a myopic to a long-term strategic planning tool.


  - Generalization to broader problem classes: Extending the framework to broader settings like network


flow optimization is a key direction for future work. The sampling-based C-SAA and C-RO-D approaches


can be directly generalized. However, the C-RO-B formulationâ€™s tractability relies on the specific problem


structure, and adapting it to more complex constraints would require new reformulations.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
35

## **Appendix**


**A.** **MILP Model Notations**


Table 4 presents the notations used in the MILP optimization model.


**Table 4** **Optimization Model Nomenclature**

**Sets**
I Set of SKUs, indexed by _ğ‘–_ .
K Set of carriers, indexed by _ğ‘˜_ .
L Set of locations, indexed by _â„“_ .
**Parameters**

inv _ğ‘–â„“_ Inventory level of SKU _ğ‘–_ at location _â„“_ when the order is placed.
cap _â„“_ Available capacity at location _â„“_ when the order is placed.
_ğ‘’_ _ğ‘–ğ‘˜â„“_ 1 if (carrier _ğ‘˜_, location _â„“_ ) is an eligible candidate location-carrier
pair for SKU _ğ‘–_ in the order and 0 otherwise.
_ğ‘_ _ğ‘–ğ‘˜â„“_ _[ğ‘ â„ğ‘–ğ‘]_ Per-unit shipping cost when using location _â„“_ and carrier _ğ‘˜_ to ship
SKU _ğ‘–_ .
_ğ‘_ _â„“_ _[ğ‘“ğ‘–ğ‘¥ğ‘’ğ‘‘]_ Per-unit fixed sourcing (non-parcel) cost when using location _ğ‘™_ .
_ğ›½_ _ğ‘˜_ Discount factor for shipping multiple units using carrier _ğ‘˜_ .
_ğ‘_ _ğ‘–_ Quantity of SKU _ğ‘–_ in the order.
_ğ‘‘_ _ğ‘˜â„“_ Delivery time deviation when using location _â„“_ and carrier _ğ‘˜_ .
_ğ›¾_ [+] Constant that converts late delivery penalty into a per-unit cost.
_ğ›¾_ [âˆ’] Constant that converts early delivery penalty into a per-unit cost.
_ğ‘_ A large number = [ï¿½] _ğ‘–_ âˆˆI _[ğ‘]_ _ğ‘–_ [+][ 2] [.]
_ğ‘€_ _ğ‘˜â„“_ A large number = [ï¿½] _ğ‘–_ âˆˆI _[ğ‘]_ _ğ‘–ğ‘˜â„“_ _[ğ‘ â„ğ‘–ğ‘]_ _[ğ‘]_ _[ğ‘–]_ [.]
**Decision Variables**
_ğ‘§_ _ğ‘–ğ‘˜â„“_ Integer decision variable which measures the quantity of SKU _ğ‘–_
in the order sourced from location _â„“_ and shipped by carrier _ğ‘˜_ .
_ğ‘¦_ _ğ‘˜â„“_ Binary decision variable which equals 1 if more than one unit is
sourced from location _â„“_ and carrier _ğ‘˜_ within the order, and equals
0 otherwise.

_ğ‘¤_ _ğ‘˜â„“_ Continuous decision variable which measures the cost to be discounted in the order using location-carrier pair ( _ğ‘˜,_ _â„“_ ) .


**B.** **Data Preprocessing**


To optimize the dataset for machine learning and optimization models, several preprocessing steps were implemented to


clean the data. Duplicate entries and rows with missing values were removed. Geographic coordinates were generated


from the zip codes of the fulfillment centers and customer locations, with any invalid zip codes discarded in the process.


The geographic distance between customer and fulfillment center locations was approximated using the Haversine


formula. Additionally, the dataset was filtered to include only carriers with sufficient order history for training prediction


models, resulting in a subset of carriers.


**C.** **Descriptive Analytics and Insights**


The company receives tens of thousands of home delivery online orders daily, with an average ranging from 30,000


to 70,000 orders. During peak hours, 500 to 2,000 orders may be received within a 15-minute time window. Direct


information regarding which carriers are available to ship specific SKUs from particular fulfillment centers is not


available in the dataset. However, heuristic rules can be derived through analyses of historical orders. The customerâ€™s


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
36


location and the dimensions/weight of the SKU(s) in an order are critical factors in determining carrier suitability.


Some carriers show a more scattered distribution of customer locations, indicating limited coverage in certain states of


the U.S.. Additionally, coverage is dependent on the location of the fulfillment center from which the order is shipped,


as some carriers can only serve a limited range around that center. In contrast, other carriers have served locations


spanning nearly the entire US. Furthermore, the upper bounds of SKU length, height, and weight in the historical data


reflect the package size and weight limits of different carriers.


**Figure 14** **Delivery Deviation Distribution of Orders Shipped by Three Example Carriers.**


The distribution of deviations varies significantly across carriers, as illustrated in Figure 14. For the first two carriers,


the majority of orders are delivered on time. The first carrier shows nearly all on-time deliveries, with the remaining


orders arriving late. The second carrier has approximately half of the orders delivered on time, with slightly more early


deliveries than late ones. In contrast, orders shipped by the last carrier predominantly arrive one day early, and most


deliveries arrive ahead of schedule. Given these pronounced differences, separate prediction models were developed


for each carrier.


**D.** **Feature Importance**


To identify the most important features for predicting deviations, a feature importance analysis was conducted using


a tree-based regression model. Two methods were examined: Mean Decrease in Impurity (MDI) and Shapley values


(SHAP). MDI measures the importance of a feature by calculating the total reduction in impurity (e.g., Gini impurity


or entropy) it brings when used in decision trees (Breiman 2001). SHAP values, on the other hand, provide a unified


measure of feature importance based on cooperative game theory, attributing to each feature its contribution to the


prediction by considering all possible feature combinations (Lundberg et al. 2020).


Figure 15 highlights the top 10 most important features evaluated, as evaluated using MDI and SHAP, for an example


carrier under a tree-based regression model. For this carrier, the planned lead time (promised delivery time) emerges


as the most significant factor. Additionally, order information such as the release time and SKU type, fulfillment center


characteristics like on-hand capacity, and carrier-specific attributes such as promised time-in-transit and carrier zone


also play important roles.


**E.** **Linearize the Objective Function of the Order Fulfillment Problem**


The nonlinear objective function _ğ‘”_ ( **z** _,_ **d** ) can be linearlized using auxiliary variables. Let **y** = ( _ğ‘¦_ _ğ‘˜â„“_ ) _ğ‘˜_ âˆˆK _,â„“_ âˆˆL âˆˆ

{0 _,_ 1} [(|K||L|)] be indicator variables, where _ğ‘¦_ _ğ‘˜â„“_ = 1 indicates more than one unit is sourced from location _â„“_ and shipped


by carrier _ğ‘˜_ within the order. Additionally, let **w** = ( _ğ‘¤_ _ğ‘˜â„“_ ) _ğ‘˜_ âˆˆK _,â„“_ âˆˆL âˆˆ R [(|K|| L|)+] be continuous variables, where _ğ‘¤_ _ğ‘˜â„“_


represents the shipping costs to be discounted in the order using carrier-location pair ( _ğ‘˜,â„“_ ).


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
37


**(a)** MDI Feature Importance. **(b)** SHAP Value Feature Importance.


**Figure 15** **Top 10 Mean Regression Features for Delivery Deviation Measured by Two Feature Importance**


**Metrics For an Example Carrier.**


The linear objective function and the additional constraints for linearization are defined as follows:



_ğ‘”_ ( **z** _,_ **d** ) =(
âˆ‘ï¸

_ğ‘–_ âˆˆI



âˆ‘ï¸

_ğ‘˜_ âˆˆK



âˆ‘ï¸ ( _ğ‘_ _â„“_ _[ğ‘“ğ‘–ğ‘¥ğ‘’ğ‘‘]_ + _ğ‘_ _ğ‘–ğ‘˜â„“_ _[ğ‘ â„ğ‘–ğ‘]_ [+] _[ ğ›¾]_ [+] _[ğ‘‘]_ [+] _ğ‘˜â„“_ [+] _[ ğ›¾]_ [âˆ’] _[ğ‘‘]_ _ğ‘˜â„“_ [âˆ’] [)] _[ğ‘§]_ _[ğ‘–ğ‘˜â„“]_ [âˆ’] âˆ‘ï¸

_â„“_ âˆˆL _ğ‘˜_ âˆˆK



âˆ‘ï¸



_ğ‘˜_ âˆˆK



_ğ›½_ _ğ‘˜_ _ğ‘¤_ _ğ‘˜â„“_ )

âˆ‘ï¸ (24)

_â„“_ âˆˆL



s.t. _ğ‘§_ _ğ‘–ğ‘˜â„“_ â‰¥ 2 âˆ’ _ğ‘_ (1 âˆ’ _ğ‘¦_ _ğ‘˜â„“_ )
âˆ‘ï¸

_ğ‘–_ âˆˆI



_ğ‘§_ _ğ‘–ğ‘˜â„“_ â‰¤ 1 + _ğ‘ğ‘¦_ _ğ‘˜â„“_

âˆ‘ï¸

_ğ‘–_ âˆˆI


_ğ‘¤_ _ğ‘˜â„“_ â‰¤ _ğ‘€_ _ğ‘˜â„“_ _ğ‘¦_ _ğ‘˜â„“_

_ğ‘¤_ _ğ‘˜â„“_ â‰¤ âˆ‘ï¸ _ğ‘_ _ğ‘–ğ‘˜â„“_ _[ğ‘ â„ğ‘–ğ‘]_ _[ğ‘§]_ _[ğ‘–ğ‘˜â„“]_ [+ (][1][ âˆ’] _[ğ‘¦]_ _[ğ‘˜â„“]_ [)] _[ğ‘€]_ _[ğ‘˜â„“]_

_ğ‘–_ âˆˆI



_,_ âˆ€ _ğ‘˜_ âˆˆK _,â„“_ âˆˆL _,_ (25)



_ğ‘¤_ _ğ‘˜â„“_ â‰¥ âˆ‘ï¸ _ğ‘_ _ğ‘–ğ‘˜â„“_ _[ğ‘ â„ğ‘–ğ‘]_ _[ğ‘§]_ _[ğ‘–ğ‘˜â„“]_ [âˆ’(][1][ âˆ’] _[ğ‘¦]_ _[ğ‘˜â„“]_ [)] _[ğ‘€]_ _[ğ‘˜â„“]_

_ğ‘–_ âˆˆI


_ğ‘¦_ _ğ‘˜â„“_ âˆˆ{0 _,_ 1}


_ğ‘¤_ _ğ‘˜â„“_ â‰¥ 0


where _ğ‘_ and _ğ‘€_ _ğ‘˜â„“_ are large constants for the big-M constraints, with their strictest values being [ï¿½] _ğ‘–_ âˆˆI _[ğ‘]_ _ğ‘–_ [+][ 2 and]
ï¿½ _ğ‘–_ âˆˆI _[ğ‘]_ _ğ‘–ğ‘˜â„“_ _[ğ‘ â„ğ‘–ğ‘]_ _[ğ‘]_ _[ğ‘–]_ [, respectively.]


**F.** **Applying the C-RO-B to CSOFP**


To successfully apply the budgeted interval uncertainty set, the uncertainty vector in the objective function _ğ‘”_ ( **z** _,_ **d** [Ëœ] )


should be element-wise positive. However, in the case of CSOFP, this requirement was not met due to the asymmetric


penalty costs associated with deviations. Instead, the uncertainty in the problem can be represented by the vector of total

costs. Let this uncertain cost vector be Ëœ **c** = ( Ëœ _ğ‘_ _ğ‘–ğ‘˜â„“_ ) _ğ‘–_ âˆˆI _,ğ‘˜_ âˆˆK _,â„“_ âˆˆL, where each Ëœ _ğ‘_ _ğ‘–ğ‘˜â„“_ = ( _ğ‘_ _â„“_ _[ğ‘“ğ‘–ğ‘¥ğ‘’ğ‘‘]_ + _ğ‘_ _ğ‘–ğ‘˜â„“_ _[ğ‘ â„ğ‘–ğ‘]_ [+] _[ ğ›¾]_ [+] [ Ëœ] _[ğ‘‘]_ [+] _ğ‘˜â„“_ [+] _[ ğ›¾]_ [âˆ’] _[ğ‘‘]_ [Ëœ] _ğ‘˜â„“_ [âˆ’] [) â‰¥] [0]


is the sum of fulfillment costs and deviation penalties for the order.


Substituting Ëœ **c** leads to:



min **z** âˆˆZ **c** Ëœ âˆˆU [max] _ğ‘_ ( **s** ) (âˆ‘ï¸

_ğ‘–_ âˆˆI



âˆ‘ï¸

_ğ‘˜_ âˆˆK



Ëœ
_ğ‘_ _ğ‘–ğ‘˜â„“_ _ğ‘§_ _ğ‘–ğ‘˜â„“_ âˆ’

âˆ‘ï¸ âˆ‘ï¸

_â„“_ âˆˆL _ğ‘˜_ âˆˆK



âˆ‘ï¸



_ğ‘˜_ âˆˆK



_ğ›½_ _ğ‘˜_ _ğ‘¤_ _ğ‘˜â„“_ ) _._

âˆ‘ï¸ (26)

_â„“_ âˆˆL


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
38


Given that the prediction interval for each _ğ‘‘_ [Ëœ] _ğ‘˜â„“_ is [ _ğ‘‘_ _ğ‘˜â„“_ _, ğ‘‘_ _ğ‘˜â„“_ + _ğ‘‘_ [Ë†] _ğ‘˜â„“_ ], where _ğ‘‘_ _ğ‘˜â„“_ and ( _ğ‘‘_ _ğ‘˜â„“_ + _ğ‘‘_ [Ë†] _ğ‘˜â„“_ ) are the estimated lower


and upper quantiles of the deviation for the carrier-location pair ( _ğ‘˜,â„“_ ), the prediction interval for Ëœ **c** can be expressed as:




[ _ğœ‰_ ~~_ğ‘–_~~ _ğ‘˜â„“_ _, ğœ‰_ _ğ‘–ğ‘˜â„“_ + _ğœ‰_ [Ë†] _ğ‘–ğ‘˜â„“_ ] = _ğ‘_ _â„“_ _[ğ‘“ğ‘–ğ‘¥ğ‘’ğ‘‘]_ + _ğ‘_ _ğ‘–ğ‘˜â„“_ _[ğ‘ â„ğ‘–ğ‘]_ [+]




[ _ğ›¾_ [âˆ’] _ğ‘‘_ [âˆ’] _ğ‘˜â„“_ _[, ğ›¾]_ [âˆ’] [(] _[ğ‘‘]_ _ğ‘˜â„“_ [+][ Ë†] _[ğ‘‘]_ _[ğ‘˜â„“]_ [)] [âˆ’] []] if _ğ‘‘_ _ğ‘˜â„“_ + _ğ‘‘_ [Ë†] _ğ‘˜â„“_ â‰¤ 0

ï£±ï£´ï£´ï£´ï£² [0 _,_ max{ _ğ›¾_ [âˆ’] _ğ‘‘_ [âˆ’] _ğ‘˜â„“_ _[, ğ›¾]_ [+] [(] _[ğ‘‘]_ _ğ‘˜â„“_ [+][ Ë†] _[ğ‘‘]_ _[ğ‘˜â„“]_ [)}]] if _ğ‘‘_ _ğ‘˜â„“_ â‰¤ 0 _, ğ‘‘_ _ğ‘˜â„“_ + _ğ‘‘_ [Ë†] _ğ‘˜â„“_ â‰¥ 0 (27)
ï£´ï£´ï£´ï£³ [ _ğ›¾_ [+] _ğ‘‘_ _ğ‘˜â„“_ _, ğ›¾_ [+] ( _ğ‘‘_ _ğ‘˜â„“_ + _ğ‘‘_ [Ë†] _ğ‘˜â„“_ )] if _ğ‘‘_ _ğ‘˜â„“_ â‰¥ 0



Let _ğµ_ âˆˆ[0 _,_ (|K||L|)] be the uncertainty budget. The contextual budgeted interval uncertainty set U _ğ‘_ ( **s** ) is expressed


as follows:


U _ğ‘_ ( **s** _, ğµ_ ) = { _ğƒ_ âˆˆ R [(|I||K|| L|)] : _ğœ‰_ _ğ‘–ğ‘˜â„“_ = _ğœ‰_ + _ğœ‰_ [Ë†] _ğ‘–ğ‘˜â„“_ _ğ›¿_ _ğ‘˜â„“_ _,_ _ğ›¿_ _ğ‘˜â„“_ â‰¤ _ğµ, ğœ¹_ âˆˆ[0 _,_ 1] [(|K|| L|)] } _._ (28)
~~_ğ‘–_~~ _ğ‘˜â„“_ âˆ‘ï¸

_ğ‘˜_ âˆˆK _,â„“_ âˆˆL


Then, with fixed **z**, the inner maximization problem of Problem (26) becomes:



max
âˆ‘ï¸

_ğ‘–_ âˆˆI


s.t.
âˆ‘ï¸



âˆ‘ï¸

_ğ‘˜_ âˆˆK



_ğœ‰_ Ë† _ğ‘–ğ‘˜â„“_ _ğ‘§_ _ğ‘–ğ‘˜â„“_ _ğ›¿_ _ğ‘˜â„“_ (29)

âˆ‘ï¸

_â„“_ âˆˆL



âˆ‘ï¸



_ğ›¿_ _ğ‘˜â„“_ â‰¤ _ğµ_ (30)

âˆ‘ï¸

_â„“_ âˆˆL



_ğ‘˜_ âˆˆK



_ğ›¿_ _ğ‘˜â„“_ âˆˆ[0 _,_ 1] _,_ âˆ€ _ğ‘˜_ âˆˆK _,â„“_ âˆˆL _._ (31)


The robust counterpart of Problem (26) is formulated as follows:



min (
**z** âˆˆZ âˆ‘ï¸

_ğ‘–_ âˆˆI



âˆ‘ï¸

_ğ‘˜_ âˆˆK



_ğœ‰_ _ğ‘§_ _ğ‘–ğ‘˜â„“_ âˆ’

âˆ‘ï¸ ~~_ğ‘–_~~ _ğ‘˜â„“_ âˆ‘ï¸

_â„“_ âˆˆL _ğ‘˜_ âˆˆK



âˆ‘ï¸



_ğ‘˜_ âˆˆK



âˆ‘ï¸



_ğ›½_ _ğ‘˜_ _ğ‘¤_ _ğ‘˜â„“_ + _ğœ‹ğµ_ +

âˆ‘ï¸ âˆ‘ï¸

_â„“_ âˆˆL _ğ‘˜_ âˆˆK



_ğ‘˜_ âˆˆK



_ğœ†_ _ğ‘˜â„“_ )

âˆ‘ï¸

_â„“_ âˆˆL



s.t. _ğœ‹_ + _ğœ†_ _ğ‘˜â„“_ â‰¥ _ğœ‰_ [Ë†] _ğ‘–ğ‘˜â„“_ _ğ‘§_ _ğ‘–ğ‘˜â„“_ _,_ âˆ€ _ğ‘–_ âˆˆI _, ğ‘˜_ âˆˆK _,â„“_ âˆˆL


_ğœ‹_ â‰¥ 0


_ğœ†_ _ğ‘˜â„“_ â‰¥ 0 _,_ âˆ€ _ğ‘˜_ âˆˆK _,â„“_ âˆˆL _,_


where _ğœ‹_ and ( _ğœ†_ _ğ‘˜â„“_ ) _ğ‘˜_ âˆˆK _,â„“_ âˆˆL are the dual variables of Constraints (30) and (31), respectively.


**G.** **Probabilistic Multi-Class Classification Using Ensemble Learning**



(32)



RF leverages multiple classification trees trained on different random subsets of the data, making predictions by

averaging the results (Breiman 2001). Let R 1 [(] _[ğ‘¡]_ [)] _[, . . .,]_ [ R] [ (] _ğ‘…_ _[ğ‘¡]_ [)] [correspond to the partitioned regions of the] _[ ğ‘¡]_ [-th tree. Given]


covariates **s**, the predicted probability for class _ğ‘_ in an RF classifier is:



_ğ‘…_
ï¿½ _ğ‘Ÿ_ =1 **[1]** [{] **[s]** [ âˆˆR] [ (] _ğ‘Ÿ_ _[ğ‘¡]_ [)] [} Â·] **[ 1]** [{] _[ğ‘‘]_ [=] _[ ğœ‰]_ _ğ‘_ [}]
_._ (33)
~~ï¿½~~ _ğ‘Ÿğ‘…_ =1 **[1]** [{] **[s]** [ âˆˆR] [ (] _ğ‘Ÿ_ _[ğ‘¡]_ [)] [}]



_ğ‘_ Ë† _ğ‘_ ( **s** ) = [1]

_ğ‘‡_



_ğ‘‡_
âˆ‘ï¸

_ğ‘¡_ =1



In contrast, GBT build classification trees sequentially, where each new tree is trained to optimize a loss function


based on the residual errors of the previous trees (Friedman 2001). Let _ğ‘…_ be the number of boosting iterations. Given


covariates **s**, for the _ğ‘Ÿ_ -th tree where _ğ‘Ÿ_ âˆˆ[ _ğ‘…_ ], let _â„_ _ğ‘Ÿ_ ( **s** ) be the prediction and _ğ›¾_ _ğ‘ğ‘Ÿ_ be the weight for class _ğ‘_ . The predicted


probability for class _ğ‘_ in a GBT classifier is obtained using the softmax function of the log-odds:

_ğ‘_ Ë† _ğ‘_ ( **s** ) = ~~ï¿½~~ _ğ¶ğ‘_ [â€²] _ğ‘’_ = _[ğº]_ 1 _[ğ‘]_ _[ğ‘’]_ [(] _[ğº]_ **[s]** [)] _[ğ‘]_ [â€²] [ (] **[s]** [)] _[,]_ (34)


with the log-odds defined as:



_ğ‘…_


_ğº_ _ğ‘_ ( **s** ) = _ğ›¾_ _ğ‘ğ‘Ÿ_ _â„_ _ğ‘Ÿ_ ( **s** ) _._ (35)

âˆ‘ï¸

_ğ‘Ÿ_ =1


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
39


**H.** **Point Prediction ML Models**


The regression models employed to generate point predictions are presented below.


1. Linear Regression (LinReg): LinReg solves the Ordinary Least Squares (OLS) problem.


2. Ridge Regression (Ridge): Ridge adds an _ğ¿_ 2 norm regularization term to the coefficients obtained from OLS.


3. Least Absolute Shrinkage and Selection Operator Regression (Lasso): Lasso adds an _ğ¿_ 1 norm regularization term


to the coefficients obtained from OLS.


4. Random Forest (RF-Reg): RF-Reg operates similarly to the Random Forest classifier described in Section G, but


it builds a collection of regression trees instead.


5. Gradient Boosted Trees (CatBoost-Reg and XGBoost-Reg): Two versions of Gradient Boosted Trees (GBT) are


implemented for regression. These GBT models are similar to the GBT classifiers described in Appendix G, except


they use regression trees. CatBoost-Reg is implemented using the CatBoost package, which builds symmetric trees


and has native support for categorical features (Prokhorenkova et al. 2018). XGBoost-Reg is implemented using the


XGBoost package (Chen and Guestrin 2016).


**Table 5** **Average Out-of-Sample MSE of Regression Models.**


Model LinReg Ridge Lasso RF-Reg CatBoost-Reg XGBoost-Reg


MSE 2.324 2.324 3.149 1.791 1.668 **1.666**


**I.** **Hyperparameters of the ML Models**


Tables 6, 7, and 8 detail the hyperparameters and corresponding search spaces employed during the model selection


and tuning processes for the ML algorithms considered in this study.


**J.** **Evaluation of the Simulator**


The simulator is compared against a baseline that uses multinomial logistic regression (MLR), a common approach in


the literature (Salari et al. 2022).


Table 9 reports the average CRPS across all carriers. The proposed calibrated MC-CLF simulator achieves a CRPS


of 0.314, compared with 0.779 for the MLR baseline, indicating a substantial improvement in distributional accuracy


at the individual-instance level.


Figure 16 overlays each simulatorâ€™s joint predicted distribution on the true empirical distribution from the test set.


The proposed calibrated MC-CLF simulator closely matches the empirical mass at zero deviation and reproduces both


early- and late-delivery tails, whereas the MLR baseline systematically overpredicts late deviations and underpredicts


on-time deliveries.


Figure 17 presents three carrier-specific examples. In each case, the proposed calibrated MC-CLF simulator aligns


tightly with the carrierâ€™s empirical distribution across all deviation classes. By contrast, the MLR baseline exhibits


clear misalignmentsâ€”particularly in the majority classes and tailsâ€”underscoring the proposed simulatorâ€™s superior


ability to capture carrier-level heterogeneity.


**K.** **Additional Details on Computational Scalability**


Table 10 provides a comprehensive comparison of objective values across different instance categories for the six


proposed CSO methods. Table 11 summarizes the computation times for the baseline models and the proposed


CSO-CLF methods.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
40


**Table 6** **Hyperparameters for Point Prediction Regression Models**


**Model** **Hyperparameter** **Range**


Ridge _ğ›¼_ ( _ğ¿_ 2 regularization) 1 _ğ‘’_ âˆ’ 4 â‰¤ _ğ›¼_ â‰¤ 10 _._ 0


Lasso _ğ›¼_ ( _ğ¿_ 1 regularization) 1 _ğ‘’_ âˆ’ 4 â‰¤ _ğ›¼_ â‰¤ 10 _._ 0



RF-Reg


CatBoost-Reg


XGBoost-Reg



n ~~e~~ stimators 100 â‰¤ n ~~e~~ stimators â‰¤ 1000 (step: 100)
max ~~d~~ epth 3 â‰¤ max ~~d~~ epth â‰¤ 10
min ~~s~~ amples ~~s~~ plit 2 â‰¤ min ~~s~~ amples ~~s~~ plit â‰¤ 10
min ~~s~~ amples ~~l~~ eaf 1 â‰¤ min ~~s~~ amples ~~l~~ eaf â‰¤ 20


iterations 50 â‰¤ iterations â‰¤ 300
depth 4 â‰¤ depth â‰¤ 10
learning rate 0 _._ 01 â‰¤ learning ~~r~~ ate â‰¤ 0 _._ 3
l2 ~~l~~ eaf ~~r~~ eg 1 â‰¤ l2 ~~l~~ eaf ~~r~~ eg â‰¤ 10
bagging ~~t~~ emperature 0 _._ 0 â‰¤ bagging ~~t~~ emperature â‰¤ 1 _._ 0
random ~~s~~ trength 0 _._ 0 â‰¤ random ~~s~~ trength â‰¤ 10 _._ 0
border ~~c~~ ount 1 â‰¤ border ~~c~~ ount â‰¤ 255
colsample ~~b~~ ylevel 0 _._ 5 â‰¤ colsample ~~b~~ ylevel â‰¤ 1 _._ 0


n ~~e~~ stimators 100 â‰¤ n ~~e~~ stimators â‰¤ 1000 (step: 100)
max ~~d~~ epth 3 â‰¤ max ~~d~~ epth â‰¤ 10
learning rate 0 _._ 01 â‰¤ learning ~~r~~ ate â‰¤ 0 _._ 3
subsample 0 _._ 5 â‰¤ subsample â‰¤ 1 _._ 0
colsample ~~b~~ ytree 0 _._ 5 â‰¤ colsample ~~b~~ ytree â‰¤ 1 _._ 0
gamma 0 â‰¤ gamma â‰¤ 5
reg ~~a~~ lpha 0 _._ 0 â‰¤ reg ~~a~~ lpha â‰¤ 100 _._ 0
reg ~~l~~ ambda 0 _._ 0 â‰¤ reg ~~l~~ ambda â‰¤ 100 _._ 0
min ~~c~~ hild weight 1 â‰¤ min ~~c~~ hild ~~w~~ eight â‰¤ 10
max ~~d~~ elta ~~s~~ tep 0 â‰¤ max ~~d~~ elta ~~s~~ tep â‰¤ 10
colsample ~~b~~ ylevel 0 _._ 5 â‰¤ colsample ~~b~~ ylevel â‰¤ 1 _._ 0
colsample ~~b~~ ynode 0 _._ 5 â‰¤ colsample ~~b~~ ynode â‰¤ 1 _._ 0



**(a)** Calibrated MC-CLF Simulator **(b)** Baseline


**Figure 16** **Overall Joint Predicted Distribution of the Simulators vs. the True Empirical Distribution**


**K.1.** **Sample Size Selection: Balancing Solution Quality and Computational Efficiency**


Figures 18 and 19 illustrate the trade-off between average realized objective value and computation time for the two


C-SAA methods.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
41


**Table 7** **Hyperparameters for Classification Models**


**Model** **Hyperparameter** **Range**


MLR C (regularization) 1 _ğ‘’_ âˆ’ 4 â‰¤ C â‰¤ 1 _ğ‘’_ 2


max ~~d~~ epth 3 â‰¤ max ~~d~~ epth â‰¤ 10
Classification Tree
min samples ~~l~~ eaf 10 â‰¤ min ~~s~~ amples ~~l~~ eaf â‰¤ 30 (step: 5)



RF-MC-CLF


CatBoost-MC-CLF



n ~~e~~ stimators 600 â‰¤ n ~~e~~ stimators â‰¤ 1000 (step: 200)
max ~~d~~ epth 3 â‰¤ max ~~d~~ epth â‰¤ 10
min samples ~~s~~ plit 2 â‰¤ min ~~s~~ amples ~~s~~ plit â‰¤ 10
min samples ~~l~~ eaf 10 â‰¤ min ~~s~~ amples ~~l~~ eaf â‰¤ 30 (step: 5)


iterations 50 â‰¤ iterations â‰¤ 300
depth 4 â‰¤ depth â‰¤ 10
learning ~~r~~ ate 0 _._ 01 â‰¤ learning ~~r~~ ate â‰¤ 0 _._ 3
l2 leaf reg 1 â‰¤ l2 ~~l~~ eaf ~~r~~ eg â‰¤ 10
bagging temperature 0 _._ 0 â‰¤ bagging ~~t~~ emperature â‰¤ 1 _._ 0
random ~~s~~ trength 0 _._ 0 â‰¤ random ~~s~~ trength â‰¤ 10 _._ 0
border ~~c~~ ount 1 â‰¤ border ~~c~~ ount â‰¤ 255
colsample ~~b~~ ylevel 0 _._ 5 â‰¤ colsample ~~b~~ ylevel â‰¤ 1 _._ 0



**Table 8** **Hyperparameters for Quantile Regression Models**


**Model** **Hyperparameter Range**


Regression Tree max ~~d~~ epth 3 â‰¤ max depth â‰¤ 10
min ~~s~~ amples ~~l~~ eaf 10 â‰¤ min ~~s~~ amples ~~l~~ eaf â‰¤ 30 (step: 10)



QRF



n ~~e~~ stimators 600 â‰¤ n ~~e~~ stimators â‰¤ 1000 (step: 200)
max ~~d~~ epth 3 â‰¤ max depth â‰¤ 10
min ~~s~~ amples ~~s~~ plit 2 â‰¤ min samples ~~s~~ plit â‰¤ 10
min ~~s~~ amples ~~l~~ eaf 10 â‰¤ min ~~s~~ amples ~~l~~ eaf â‰¤ 30 (step: 5)


**Table 9** **Average In-Sample CRPS Across All Carriers.**



Model Calibrated MC-CLF Simulator MLR Simulator (Baseline)


CRPS 0.314 0.779


**Table 10** **Realized Average (** Â± **95% CI margin of error) and Worst-Case Objective Values Across Instance**


**Categories.**


Instance C-SAA-CLF C-SAA-QRF C-RO-B-CLF C-RO-B-QRF C-RO-D-CLF C-RO-D-QRF


Avg Worst Avg Worst Avg Worst Avg Worst Avg Worst Avg Worst


Small 0 _._ 821 Â± 0 _._ 003 0.790 0 _._ 848 Â± 0 _._ 004 0.813 0 _._ 851 Â± 0 _._ 004 0.794 0 _._ 871 Â± 0 _._ 003 0.813 0 _._ 936 Â± 0 _._ 004 0.757 0 _._ 920 Â± 0 _._ 004 0.766

Medium 0 _._ 799 Â± 0 _._ 008 0.932 0 _._ 806 Â± 0 _._ 009 0.925 0 _._ 797 Â± 0 _._ 009 0.834 0 _._ 815 Â± 0 _._ 009 0.821 0 _._ 890 Â± 0 _._ 010 0.822 0 _._ 883 Â± 0 _._ 009 0.825
Large 0 _._ 847 Â± 0 _._ 012 1.032 0 _._ 871 Â± 0 _._ 017 1.055 0 _._ 823 Â± 0 _._ 014 0.982 0 _._ 836 Â± 0 _._ 016 0.981 0 _._ 910 Â± 0 _._ 017 0.972 0 _._ 904 Â± 0 _._ 014 0.973


Total 0 _._ 820 Â± 0 _._ 003 0.823 0 _._ 844 Â± 0 _._ 003 0.842 0 _._ 842 Â± 0 _._ 003 0.811 0 _._ 861 Â± 0 _._ 003 0.824 0 _._ 928 Â± 0 _._ 003 0.779 0 _._ 914 Â± 0 _._ 003 0.787


**Table 11** **Computation Time Statistics (in seconds) Across Instance Categories.**


Instance C-SAA-CLF C-RO-B-CLF C-RO-D-CLF C-Empirical-SAA Empirical-SAA PTO Greedy


Avg Std Max Avg Std Max Avg Std Max Avg Std Max Avg Std Max Avg Std Max Avg Std Max


Small 1.620 2.267 28.021 0.016 0.024 0.374 0.199 0.301 5.475 2.520 3.552 46.90 2.510 3.547 46.86 0.014 0.021 0.684 0.001 0.001 0.008

Medium 27.831 10.245 107.347 0.281 0.106 0.860 3.229 2.008 39.222 43.742 16.475 165.717 43.864 16.678 179.577 0.243 0.103 1.027 0.013 0.007 0.060
Large 59.266 22.590 182.401 0.698 0.322 2.856 7.683 7.056 111.188 91.190 35.100 278.677 92.225 35.421 295.212 0.629 0.329 2.584 0.052 0.034 0.317


Total 8.974 17.433 182.401 0.096 0.203 2.856 1.101 2.791 111.188 13.959 27.052 278.677 14.033 27.304 295.212 0.086 0.187 2.584 0.006 0.016 0.317


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
42


**(a)** Example Carrier 1: Calibrated MC-CLF Simulator **(b)** Example Carrier 1: Baseline


**(c)** Example Carrier 2: Calibrated MC-CLF Simulator **(d)** Example Carrier 2: Baseline


**(e)** Example Carrier 3: Calibrated MC-CLF Simulator **(f)** Example Carrier 3: Baseline


**Figure 17** **Selected Carrier Examples: Joint Predicted Distribution of the Simulators vs. the True Empirical**


**Distribution**


Similarly, Figures 20 and 21 depict the trade-off between worst-case realized objective value and computation time


for the two C-RO-D methods.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
43


**(a)** Small Instances. **(b)** Medium Instances. **(c)** Large Instances.


**Figure 18** **Computation Time by C-SAA Sample Size.**


**(a)** Small Instances. **(b)** Medium Instances. **(c)** Large Instances.


**Figure 19** **Average Realized Objective Value by C-SAA Sample Size.**


**(a)** Small Instances. **(b)** Medium Instances. **(c)** Large Instances.


**Figure 20** **Computation Time by C-RO-D Sample Size.**


**(a)** Small Instances. **(b)** Medium Instances. **(c)** Large Instances.


**Figure 21** **Worst-Case Realized Objective Value by C-RO-D Sample Size.**


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
44

## **References**


Acimovic J, Farias VF (2019) The fulfillment-optimization problem. _Operations Research & Management Science in_


_the age of analytics_, 218â€“237 (INFORMS).


Acimovic J, Graves SC (2015) Making better fulfillment decisions on the fly in an online retail environment. _Manu-_


_facturing & Service Operations Management_ 17(1):34â€“51.


Akiba T, Sano S, Yanase T, Ohta T, Koyama M (2019) Optuna: A next-generation hyperparameter optimization


framework. _Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data_


_mining_, 2623â€“2631.


Bayram V, Baloch G, Gzara F, Elhedhli S (2022) Optimal order batching in warehouse management: A data-driven


robust approach. _INFORMS Journal on Optimization_ 4(3):278â€“303.


Behrendt A, Savelsbergh M, Wang H (2023) A prescriptive machine learning method for courier scheduling on


crowdsourced delivery platforms. _Transportation Science_ 57(4):889â€“907.


Bertsimas D, Den Hertog D, Pauphilet J (2021) Probabilistic guarantees in robust optimization. _SIAM Journal on_


_Optimization_ 31(4):2893â€“2920.


Bertsimas D, Dunn J, Mundru N (2019) Optimal prescriptive trees. _INFORMS Journal on Optimization_ 1(2):164â€“183.


Bertsimas D, Kallus N (2020) From predictive to prescriptive analytics. _Management Science_ 66(3):1025â€“1044.


Bertsimas D, Kallus N, Hussain A (2016) Inventory management in the era of big data. _Production and operations_


_management_ 25(12):2006â€“2009, URL http://dx.doi.org/10.1111/poms.2\{_}12637.


Bertsimas D, Sim M (2004) The price of robustness. _Operations research_ 52(1):35â€“53.


Breiman L (2001) Random forests. _Machine learning_ 45:5â€“32.


Calafiore GC, Campi MC (2006) The scenario approach to robust control design. _IEEE Transactions on automatic_


_control_ 51(5):742â€“753.


Campi MC, Garatti S (2008) The exact feasibility of randomized solutions of uncertain convex programs. _SIAM Journal_


_on Optimization_ 19(3):1211â€“1230.


Chen S, Yan Z, Lim YF (2024) Managing the personalized Order-Holding problem in online retailing. _Manufacturing_


_& Service Operations Management_ 26(1):47â€“65, URL http://dx.doi.org/10.1287/msom.2023.


1201.


Chen T, Guestrin C (2016) XGBoost: A scalable tree boosting system. _Proceedings of the 22nd ACM SIGKDD_


_International Conference on Knowledge Discovery and Data Mining_, 785â€“794, KDD â€™16 (New York, NY, USA:


ACM), ISBN 978-1-4503-4232-2, URL http://dx.doi.org/10.1145/2939672.2939785.


Cui R, Lu Z, Sun T, Golden JM (2024) Sooner or later? promising delivery speed in online retail. _Manufacturing &_


_Service Operations Management_ 26(1):233â€“251.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
45


Das S, Ravi R, Sridhar S (2023) Order fulfillment under pick failure in omnichannel Ship-From-Store programs.


_Manufacturing & service operations management_ 25(2):508â€“523, URL http://dx.doi.org/10.1287/


msom.2022.1164.


Deng Y, Sen S (2022) Predictive stochastic programming. _Computational Management Science_ 19(1):65â€“98.


Dethlefs C, Ostermeier M, HÂ¨ubner A (2022) Rapid fulfillment of online orders in omnichannel grocery retail

ing. _EURO journal on transportation and logistics_ 11:100082, URL http://dx.doi.org/10.1016/j.


ejtl.2022.100082.


DeValve L, Wei Y, Wu D, Yuan R (2023) Understanding the value of fulfillment flexibility in an online retailing


environment. _Manufacturing & service operations management_ 25(2):391â€“408.


Elmachtoub AN, Grigas P (2022) Smart â€œpredict, then optimizeâ€. _Management Science_ 68(1):9â€“26.


Fisher ML, Gallino S, Xu JJ (2019) The value of rapid delivery in omnichannel retailing. _Journal of marketing research_


56(5):732â€“748, URL http://dx.doi.org/10.1177/0022243719849940.


Freedman L (2019) Why logistics have never been more important to online retail

ersâ€™ success. URL https://www.digitalcommerce360.com/2019/09/30/


why-logistics-have-never-been-more-important-to-online-retailers-success/.


Friedman JH (2001) Greedy function approximation: a gradient boosting machine. _Annals of statistics_ 1189â€“1232.


Guan H, Gillani N, Simko T, Mangat J, Van Hentenryck P (2024) Contextual stochastic optimization for school


desegregation policymaking. _arXiv preprint arXiv:2408.12572_ .


HÂ¨ubner AH, Kuhn H, Sternbeck MG (2013) Demand and supply chain planning in grocery retail: an operations


planning framework. _International journal of retail & distribution management_ 41(7):512â€“530, URL http:


//dx.doi.org/10.1108/ijrdm-05-2013-0104.


Ito S, Fujimaki R (2016) Optimization beyond prediction: Prescriptive price optimization. URL https://arxiv.


org/abs/1605.05422.


Jasin S, Sinha A(2015) An lp-basedcorrelated rounding schemefor multi-item ecommerceorder fulfillment. _Operations_


_Research_ 63(6):1336â€“1351.


Jo N, Aghaei S, GÂ´omez A, Vayanos P (2021) Learning optimal prescriptive trees from observational data. _arXiv preprint_


_arXiv:2108.13628_ .


Johnson RA (2024) quantile-forest: A python package for quantile regression forests. _Journal of Open Source Software_


9(93):5976, URL http://dx.doi.org/10.21105/joss.05976.


Kallus N, Mao X (2023) Stochastic optimization forests. _Management Science_ 69(4):1975â€“1994.


Kandula S, Krishnamoorthy S, Roy D (2021) A prescriptive analytics framework for efficient e-commerce order


delivery. _Decision Support Systems_ 147:113584.


Kannan R, Bayraksan G, Luedtke JR (2023) Residuals-based distributionally robust optimization with covariate


information. _Mathematical Programming_ 1â€“57.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
46


Kleywegt AJ, Shapiro A, Homem-de Mello T (2002) The sample average approximation method for stochastic discrete


optimization. _SIAM Journal on optimization_ 12(2):479â€“502.


Kuhn H, Sternbeck MG (2013) Integrative retail logistics: An exploratory study. _Operations management_


_research/Operations management research : advancing practice through research_ 6(1-2):2â€“18, URL http:


//dx.doi.org/10.1007/s12063-012-0075-9.


Lattimore T, SzepesvÂ´ari C (2020) _Bandit algorithms_ (Cambridge University Press).


Liu S, He L, Max Shen ZJ (2021) On-time last-mile delivery: Order assignment with travel-time predictors. _Management_


_Science_ 67(7):4095â€“4119.


Lundberg SM, Erion G, Chen H, DeGrave A, Prutkin JM, Nair B, Katz R, Himmelfarb J, Bansal N, Lee SI (2020)


From local explanations to global understanding with explainable ai for trees. _Nature Machine Intelligence_


2(1):2522â€“5839.


Ma W (2023) Order-optimal correlated rounding for fulfilling multi-item e-commerce orders. _Manufacturing & Service_


_Operations Management_ .


Meinshausen N, Ridgeway G (2006) Quantile regression forests. _Journal of machine learning research_ 7(6).


Meller J, Taigel F, Pibernik R (2018) Prescriptive Analytics for Inventory Management: A comparison of New


approaches. _Social Science Research Network_ URL http://dx.doi.org/10.2139/ssrn.3229105.


MiË‡siÂ´c VV, Perakis G (2020) Data analytics in operations management: A review. _Manufacturing & Service Operations_


_Management_ 22(1):158â€“169.


Mohri SS, Ghaderi H, Nassir N, Thompson RG (2023) Crowdshipping for sustainable urban logistics: A systematic


review of the literature. _Transportation research. Part E, Logistics and transportation review_ 178:103289, URL


http://dx.doi.org/10.1016/j.tre.2023.103289.


Niculescu-Mizil A, Caruana R (2005) Predicting good probabilities with supervised learning. _Proceedings of the 22nd_


_international conference on Machine learning_, 625â€“632.


Notz PM, Pibernik R (2022) Prescriptive analytics for flexible capacity management. _Management Science_ 68(3):1756â€“


1775.


Patel YP, Rayan S, Tewari A (2024) Conformal contextual robust optimization. _International Conference on Artificial_


_Intelligence and Statistics_, 2485â€“2493 (PMLR).


Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, Blondel M, Prettenhofer P, Weiss R, Dubourg


V, Vanderplas J, Passos A, Cournapeau D, Brucher M, Perrot M, Duchesnay E (2011) Scikit-learn: Machine


learning in python. _Journal of Machine Learning Research_ 12:2825â€“2830.


Perakis G, Sim M, Tang Q, Xiong P (2023) Robust pricing and production with information partitioning and adaptation.


_Management Science_ 69(3):1398â€“1419.


PerË‡sak E, Anjos MF (2023) Contextual robust optimisation with uncertainty quantification. _International Conference_


_on Integration of Constraint Programming, Artificial Intelligence, and Operations Research_, 124â€“132 (Springer).


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
47


Prokhorenkova L, Gusev G, Vorobev A, Dorogush AV, Gulin A (2018) Catboost: unbiased boosting with categorical


features. _Advances in Neural Information Processing Systems_ 31.


Qi M, Grigas P, Shen ZJM (2021) Integrated conditional estimation-optimization. _arXiv preprint arXiv:2110.12351_ .


Qi M, Shen ZJ (2022) Integrating prediction/estimation and optimization with applications in operations management.


_Tutorials in Operations Research: Emerging and Impactful Topics in Operations_, 36â€“58 (INFORMS).


Raj G, Roy D, de Koster R, Bansal V (2024) Stochastic modeling of integrated order fulfillment processes with delivery


time promise: Order picking, batching, and last-mile delivery. _European Journal of Operational Research_ .


Sadana U, Chenreddy A, Delage E, Forel A, Frejinger E, Vidal T (2024) A survey of contextual optimization methods


for decision-making under uncertainty. _European Journal of Operational Research_ .


Salari N, Liu S, Shen ZJM (2022) Real-time delivery time forecasting and promising in online retailing: When will


your package arrive? _Manufacturing & Service Operations Management_ 24(3):1421â€“1436.


Shapiro A, Dentcheva D, Ruszczynski A (2021) _Lectures on stochastic programming: modeling and theory_ (SIAM).


Sun C, Liu L, Li X (2024) Predict-then-calibrate: A new perspective of robust contextual lp. _Advances in Neural_


_Information Processing Systems_ 36.


Tian X, Yan R, Wang S, Liu Y, Zhen L (2023) Tutorial on prescriptive analytics for logistics: What to predict and how


to predict. _Electronic Research Archive_ .


Â¨UlkÂ¨u MA (2012) Dare to care: Shipment consolidation reduces not only costs, but also environmental damage.


_International Journal of Production Economics_ 139(2):438â€“446.


US Department of Commerce (2024) QUARTERLY RETAIL E-COMMERCE SALES. URL https://www.


census.gov/retail/mrts/www/data/pdf/ec_current.pdf.


Viswanathan A (2023) Elevating the last mile: Transformative trends and customer

centric evolution in e-commerce. URL https://www.scmr.com/article/


elevating-the-last-mile-transformative-tends-in-ecommerce, accessed: 2024-07-05.


Wagner L, Calvo E, Amorim P (2023) Better Together! The Consumer Implications of Delivery Consolidation.


_Manufacturing & Service Operations Management_ 25(3):903â€“920, URL http://dx.doi.org/10.1287/


msom.2023.1200.


Wei L, Kapuscinski R, Jasin S (2021) Shipping consolidation across two warehouses with delivery deadline and


expedited options for e-commerce and omni-channel retailers. _Manufacturing & Service Operations Management_


23(6):1634â€“1650.


Xu PJ, Allgor R, Graves SC (2009) Benefits of reevaluating real-time order fulfillment decisions. _Manufacturing &_


_Service Operations Management_ 11(2):340â€“355.


Zadrozny B, Elkan C (2002) Transforming classifier scores into accurate multiclass probability estimates. _Proceedings_


_of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining_, 694â€“699.


**Ye et al.:** _Contextual Stochastic Optimization for Order Fulfillment Optimization_
48


Zehtabian S, Larsen C, WÃ¸hlk S (2022) Estimation of the arrival time of deliveries by occasional drivers in a crowd

shipping setting. _European journal of operational research_ 303(2):616â€“632, URL http://dx.doi.org/


10.1016/j.ejor.2022.02.050.


Zhao Y, Wang X, Xin L (2020) Multi-Item Online Order Fulfillment: A Competitive analysis. _SSRN Electronic Journal_


URL http://dx.doi.org/10.2139/ssrn.3675117.


